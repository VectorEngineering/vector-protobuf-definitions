// Code generated by gorm.io/gen. DO NOT EDIT.
// Code generated by gorm.io/gen. DO NOT EDIT.
// Code generated by gorm.io/gen. DO NOT EDIT.

package dal

import (
	"context"
	"strings"

	lead_scraper_servicev1 "github.com/VectorEngineering/vector-protobuf-definitions/api-definitions/pkg/generated/lead_scraper_service/v1"
	"gorm.io/gorm"
	"gorm.io/gorm/clause"
	"gorm.io/gorm/schema"

	"gorm.io/gen"
	"gorm.io/gen/field"
	"gorm.io/gen/helper"

	"gorm.io/plugin/dbresolver"

	"time"
)

func newScrapingJobORM(db *gorm.DB, opts ...gen.DOOption) scrapingJobORM {
	_scrapingJobORM := scrapingJobORM{}

	_scrapingJobORM.scrapingJobORMDo.UseDB(db, opts...)
	_scrapingJobORM.scrapingJobORMDo.UseModel(&lead_scraper_servicev1.ScrapingJobORM{})

	tableName := _scrapingJobORM.scrapingJobORMDo.TableName()
	_scrapingJobORM.ALL = field.NewAsterisk(tableName)
	_scrapingJobORM.AccountId = field.NewUint64(tableName, "account_id")
	_scrapingJobORM.CreatedAt = field.NewTime(tableName, "created_at")
	_scrapingJobORM.DeletedAt = field.NewTime(tableName, "deleted_at")
	_scrapingJobORM.Depth = field.NewInt32(tableName, "depth")
	_scrapingJobORM.Email = field.NewBool(tableName, "email")
	_scrapingJobORM.FastMode = field.NewBool(tableName, "fast_mode")
	_scrapingJobORM.Id = field.NewString(tableName, "id")
	_scrapingJobORM.Keywords = field.NewField(tableName, "keywords")
	_scrapingJobORM.Lang = field.NewString(tableName, "lang")
	_scrapingJobORM.Lat = field.NewString(tableName, "lat")
	_scrapingJobORM.Lon = field.NewString(tableName, "lon")
	_scrapingJobORM.MaxTime = field.NewInt32(tableName, "max_time")
	_scrapingJobORM.Name = field.NewString(tableName, "name")
	_scrapingJobORM.NumLeadsCollected = field.NewInt32(tableName, "num_leads_collected")
	_scrapingJobORM.Payload = field.NewBytes(tableName, "payload")
	_scrapingJobORM.PayloadType = field.NewString(tableName, "payload_type")
	_scrapingJobORM.Priority = field.NewInt32(tableName, "priority")
	_scrapingJobORM.Proxies = field.NewField(tableName, "proxies")
	_scrapingJobORM.Radius = field.NewInt32(tableName, "radius")
	_scrapingJobORM.ScrapingWorkflowId = field.NewUint64(tableName, "scraping_workflow_id")
	_scrapingJobORM.Status = field.NewString(tableName, "status")
	_scrapingJobORM.UpdatedAt = field.NewTime(tableName, "updated_at")
	_scrapingJobORM.Zoom = field.NewInt32(tableName, "zoom")

	_scrapingJobORM.fillFieldMap()

	return _scrapingJobORM
}

type scrapingJobORM struct {
	scrapingJobORMDo

	ALL                field.Asterisk
	AccountId          field.Uint64
	CreatedAt          field.Time
	DeletedAt          field.Time
	Depth              field.Int32
	Email              field.Bool
	FastMode           field.Bool
	Id                 field.String
	Keywords           field.Field
	Lang               field.String
	Lat                field.String
	Lon                field.String
	MaxTime            field.Int32
	Name               field.String
	NumLeadsCollected  field.Int32
	Payload            field.Bytes
	PayloadType        field.String
	Priority           field.Int32
	Proxies            field.Field
	Radius             field.Int32
	ScrapingWorkflowId field.Uint64
	Status             field.String
	UpdatedAt          field.Time
	Zoom               field.Int32

	fieldMap map[string]field.Expr
}

func (s scrapingJobORM) Table(newTableName string) *scrapingJobORM {
	s.scrapingJobORMDo.UseTable(newTableName)
	return s.updateTableName(newTableName)
}

func (s scrapingJobORM) As(alias string) *scrapingJobORM {
	s.scrapingJobORMDo.DO = *(s.scrapingJobORMDo.As(alias).(*gen.DO))
	return s.updateTableName(alias)
}

func (s *scrapingJobORM) updateTableName(table string) *scrapingJobORM {
	s.ALL = field.NewAsterisk(table)
	s.AccountId = field.NewUint64(table, "account_id")
	s.CreatedAt = field.NewTime(table, "created_at")
	s.DeletedAt = field.NewTime(table, "deleted_at")
	s.Depth = field.NewInt32(table, "depth")
	s.Email = field.NewBool(table, "email")
	s.FastMode = field.NewBool(table, "fast_mode")
	s.Id = field.NewString(table, "id")
	s.Keywords = field.NewField(table, "keywords")
	s.Lang = field.NewString(table, "lang")
	s.Lat = field.NewString(table, "lat")
	s.Lon = field.NewString(table, "lon")
	s.MaxTime = field.NewInt32(table, "max_time")
	s.Name = field.NewString(table, "name")
	s.NumLeadsCollected = field.NewInt32(table, "num_leads_collected")
	s.Payload = field.NewBytes(table, "payload")
	s.PayloadType = field.NewString(table, "payload_type")
	s.Priority = field.NewInt32(table, "priority")
	s.Proxies = field.NewField(table, "proxies")
	s.Radius = field.NewInt32(table, "radius")
	s.ScrapingWorkflowId = field.NewUint64(table, "scraping_workflow_id")
	s.Status = field.NewString(table, "status")
	s.UpdatedAt = field.NewTime(table, "updated_at")
	s.Zoom = field.NewInt32(table, "zoom")

	s.fillFieldMap()

	return s
}

func (s *scrapingJobORM) GetFieldByName(fieldName string) (field.OrderExpr, bool) {
	_f, ok := s.fieldMap[fieldName]
	if !ok || _f == nil {
		return nil, false
	}
	_oe, ok := _f.(field.OrderExpr)
	return _oe, ok
}

func (s *scrapingJobORM) fillFieldMap() {
	s.fieldMap = make(map[string]field.Expr, 23)
	s.fieldMap["account_id"] = s.AccountId
	s.fieldMap["created_at"] = s.CreatedAt
	s.fieldMap["deleted_at"] = s.DeletedAt
	s.fieldMap["depth"] = s.Depth
	s.fieldMap["email"] = s.Email
	s.fieldMap["fast_mode"] = s.FastMode
	s.fieldMap["id"] = s.Id
	s.fieldMap["keywords"] = s.Keywords
	s.fieldMap["lang"] = s.Lang
	s.fieldMap["lat"] = s.Lat
	s.fieldMap["lon"] = s.Lon
	s.fieldMap["max_time"] = s.MaxTime
	s.fieldMap["name"] = s.Name
	s.fieldMap["num_leads_collected"] = s.NumLeadsCollected
	s.fieldMap["payload"] = s.Payload
	s.fieldMap["payload_type"] = s.PayloadType
	s.fieldMap["priority"] = s.Priority
	s.fieldMap["proxies"] = s.Proxies
	s.fieldMap["radius"] = s.Radius
	s.fieldMap["scraping_workflow_id"] = s.ScrapingWorkflowId
	s.fieldMap["status"] = s.Status
	s.fieldMap["updated_at"] = s.UpdatedAt
	s.fieldMap["zoom"] = s.Zoom
}

func (s scrapingJobORM) clone(db *gorm.DB) scrapingJobORM {
	s.scrapingJobORMDo.ReplaceConnPool(db.Statement.ConnPool)
	return s
}

func (s scrapingJobORM) replaceDB(db *gorm.DB) scrapingJobORM {
	s.scrapingJobORMDo.ReplaceDB(db)
	return s
}

type scrapingJobORMDo struct{ gen.DO }

type IScrapingJobORMDo interface {
	gen.SubQuery
	Debug() IScrapingJobORMDo
	WithContext(ctx context.Context) IScrapingJobORMDo
	WithResult(fc func(tx gen.Dao)) gen.ResultInfo
	ReplaceDB(db *gorm.DB)
	ReadDB() IScrapingJobORMDo
	WriteDB() IScrapingJobORMDo
	As(alias string) gen.Dao
	Session(config *gorm.Session) IScrapingJobORMDo
	Columns(cols ...field.Expr) gen.Columns
	Clauses(conds ...clause.Expression) IScrapingJobORMDo
	Not(conds ...gen.Condition) IScrapingJobORMDo
	Or(conds ...gen.Condition) IScrapingJobORMDo
	Select(conds ...field.Expr) IScrapingJobORMDo
	Where(conds ...gen.Condition) IScrapingJobORMDo
	Order(conds ...field.Expr) IScrapingJobORMDo
	Distinct(cols ...field.Expr) IScrapingJobORMDo
	Omit(cols ...field.Expr) IScrapingJobORMDo
	Join(table schema.Tabler, on ...field.Expr) IScrapingJobORMDo
	LeftJoin(table schema.Tabler, on ...field.Expr) IScrapingJobORMDo
	RightJoin(table schema.Tabler, on ...field.Expr) IScrapingJobORMDo
	Group(cols ...field.Expr) IScrapingJobORMDo
	Having(conds ...gen.Condition) IScrapingJobORMDo
	Limit(limit int) IScrapingJobORMDo
	Offset(offset int) IScrapingJobORMDo
	Count() (count int64, err error)
	Scopes(funcs ...func(gen.Dao) gen.Dao) IScrapingJobORMDo
	Unscoped() IScrapingJobORMDo
	Create(values ...*lead_scraper_servicev1.ScrapingJobORM) error
	CreateInBatches(values []*lead_scraper_servicev1.ScrapingJobORM, batchSize int) error
	Save(values ...*lead_scraper_servicev1.ScrapingJobORM) error
	First() (*lead_scraper_servicev1.ScrapingJobORM, error)
	Take() (*lead_scraper_servicev1.ScrapingJobORM, error)
	Last() (*lead_scraper_servicev1.ScrapingJobORM, error)
	Find() ([]*lead_scraper_servicev1.ScrapingJobORM, error)
	FindInBatch(batchSize int, fc func(tx gen.Dao, batch int) error) (results []*lead_scraper_servicev1.ScrapingJobORM, err error)
	FindInBatches(result *[]*lead_scraper_servicev1.ScrapingJobORM, batchSize int, fc func(tx gen.Dao, batch int) error) error
	Pluck(column field.Expr, dest interface{}) error
	Delete(...*lead_scraper_servicev1.ScrapingJobORM) (info gen.ResultInfo, err error)
	Update(column field.Expr, value interface{}) (info gen.ResultInfo, err error)
	UpdateSimple(columns ...field.AssignExpr) (info gen.ResultInfo, err error)
	Updates(value interface{}) (info gen.ResultInfo, err error)
	UpdateColumn(column field.Expr, value interface{}) (info gen.ResultInfo, err error)
	UpdateColumnSimple(columns ...field.AssignExpr) (info gen.ResultInfo, err error)
	UpdateColumns(value interface{}) (info gen.ResultInfo, err error)
	UpdateFrom(q gen.SubQuery) gen.Dao
	Attrs(attrs ...field.AssignExpr) IScrapingJobORMDo
	Assign(attrs ...field.AssignExpr) IScrapingJobORMDo
	Joins(fields ...field.RelationField) IScrapingJobORMDo
	Preload(fields ...field.RelationField) IScrapingJobORMDo
	FirstOrInit() (*lead_scraper_servicev1.ScrapingJobORM, error)
	FirstOrCreate() (*lead_scraper_servicev1.ScrapingJobORM, error)
	FindByPage(offset int, limit int) (result []*lead_scraper_servicev1.ScrapingJobORM, count int64, err error)
	ScanByPage(result interface{}, offset int, limit int) (count int64, err error)
	Scan(result interface{}) (err error)
	Returning(value interface{}, columns ...string) IScrapingJobORMDo
	UnderlyingDB() *gorm.DB
	schema.Tabler

	GetRecordByID(id uint64) (result lead_scraper_servicev1.ScrapingJobORM, err error)
	GetRecordByIDs(ids []uint64) (result []lead_scraper_servicev1.ScrapingJobORM, err error)
	DeleteRecordByID(id uint64) (err error)
	GetAllRecords(orderColumn string, limit int, offset int) (result []lead_scraper_servicev1.ScrapingJobORM, err error)
	CountAll() (result int, err error)
	GetByID(id uint64) (result lead_scraper_servicev1.ScrapingJobORM, err error)
	GetByIDs(ids []uint64) (result []lead_scraper_servicev1.ScrapingJobORM, err error)
	GetActivePaginated(orderColumn string, limit int, offset int) (result []lead_scraper_servicev1.ScrapingJobORM, err error)
	GetDeleted() (result []lead_scraper_servicev1.ScrapingJobORM, err error)
	SoftDelete(id uint64) (err error)
	Restore(id uint64) (err error)
	CreateInBatch(items []lead_scraper_servicev1.ScrapingJobORM, batchSize int) (err error)
	DeleteInBatch(ids []uint64) (err error)
	GetByTimeRange(startTime time.Time, endTime time.Time) (result []lead_scraper_servicev1.ScrapingJobORM, err error)
	FindBy(columnName string, operator string, value interface{}) (result []lead_scraper_servicev1.ScrapingJobORM, err error)
	FindByPattern(columnName string, pattern string) (result []lead_scraper_servicev1.ScrapingJobORM, err error)
	GetDistinct(columnName string) (result []lead_scraper_servicev1.ScrapingJobORM, err error)
	FindWithFilters(conditions map[string]interface{}, orderBy string, limit int, offset int) (result []lead_scraper_servicev1.ScrapingJobORM, err error)
	Touch(id uint64) (err error)
	Exists(column string, value interface{}) (result bool, err error)
	ExistsById(id uint64) (result bool, err error)
	FindBySubquery(column string, foreignTable string, foreignKey string) (result []lead_scraper_servicev1.ScrapingJobORM, err error)
	ExistsAndGet(column string, value interface{}) (result lead_scraper_servicev1.ScrapingJobORM, err error)
	ExistsAndGetActive(column string, value interface{}) (result lead_scraper_servicev1.ScrapingJobORM, err error)
}

// SELECT * FROM @@table
// {{where}}
//
//	id=@id
//
// {{end}}
func (s scrapingJobORMDo) GetRecordByID(id uint64) (result lead_scraper_servicev1.ScrapingJobORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM gmaps_jobs ")
	var whereSQL0 strings.Builder
	params = append(params, id)
	whereSQL0.WriteString("id=? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Take(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// {{where}}
//
//	id IN (@ids)
//
// {{end}}
func (s scrapingJobORMDo) GetRecordByIDs(ids []uint64) (result []lead_scraper_servicev1.ScrapingJobORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM gmaps_jobs ")
	var whereSQL0 strings.Builder
	params = append(params, ids)
	whereSQL0.WriteString("id IN (?) ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// DELETE FROM @@table
// {{where}}
//
//	id=@id
//
// {{end}}
func (s scrapingJobORMDo) DeleteRecordByID(id uint64) (err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("DELETE FROM gmaps_jobs ")
	var whereSQL0 strings.Builder
	params = append(params, id)
	whereSQL0.WriteString("id=? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Exec(generateSQL.String(), params...) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// ORDER BY @@orderColumn
// LIMIT @limit
// OFFSET @offset
func (s scrapingJobORMDo) GetAllRecords(orderColumn string, limit int, offset int) (result []lead_scraper_servicev1.ScrapingJobORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	params = append(params, limit)
	params = append(params, offset)
	generateSQL.WriteString("SELECT * FROM gmaps_jobs ORDER BY " + s.Quote(orderColumn) + " LIMIT ? OFFSET ? ")

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// Additional Operations
// SELECT COUNT(*) FROM @@table
func (s scrapingJobORMDo) CountAll() (result int, err error) {
	var generateSQL strings.Builder
	generateSQL.WriteString("Additional Operations SELECT COUNT(*) FROM gmaps_jobs ")

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String()).Take(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// {{where}}
//
//	id=@id
//
// {{end}}
func (s scrapingJobORMDo) GetByID(id uint64) (result lead_scraper_servicev1.ScrapingJobORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM gmaps_jobs ")
	var whereSQL0 strings.Builder
	params = append(params, id)
	whereSQL0.WriteString("id=? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Take(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// {{where}}
//
//	id IN (@ids)
//
// {{end}}
func (s scrapingJobORMDo) GetByIDs(ids []uint64) (result []lead_scraper_servicev1.ScrapingJobORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM gmaps_jobs ")
	var whereSQL0 strings.Builder
	params = append(params, ids)
	whereSQL0.WriteString("id IN (?) ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// {{where}}
//
//	deleted_at IS NULL
//
// {{end}}
// ORDER BY @@orderColumn
// LIMIT @limit OFFSET @offset
func (s scrapingJobORMDo) GetActivePaginated(orderColumn string, limit int, offset int) (result []lead_scraper_servicev1.ScrapingJobORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM gmaps_jobs ")
	var whereSQL0 strings.Builder
	whereSQL0.WriteString("deleted_at IS NULL ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)
	params = append(params, limit)
	params = append(params, offset)
	generateSQL.WriteString("ORDER BY " + s.Quote(orderColumn) + " LIMIT ? OFFSET ? ")

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// {{where}}
//
//	deleted_at IS NOT NULL
//
// {{end}}
func (s scrapingJobORMDo) GetDeleted() (result []lead_scraper_servicev1.ScrapingJobORM, err error) {
	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM gmaps_jobs ")
	var whereSQL0 strings.Builder
	whereSQL0.WriteString("deleted_at IS NOT NULL ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String()).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// UPDATE @@table SET deleted_at=CURRENT_TIMESTAMP
// {{where}}
//
//	id=@id
//
// {{end}}
func (s scrapingJobORMDo) SoftDelete(id uint64) (err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("UPDATE gmaps_jobs SET deleted_at=CURRENT_TIMESTAMP ")
	var whereSQL0 strings.Builder
	params = append(params, id)
	whereSQL0.WriteString("id=? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Exec(generateSQL.String(), params...) // ignore_security_alert
	err = executeSQL.Error

	return
}

// UPDATE @@table SET deleted_at=NULL
// {{where}}
//
//	id=@id
//
// {{end}}
func (s scrapingJobORMDo) Restore(id uint64) (err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("UPDATE gmaps_jobs SET deleted_at=NULL ")
	var whereSQL0 strings.Builder
	params = append(params, id)
	whereSQL0.WriteString("id=? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Exec(generateSQL.String(), params...) // ignore_security_alert
	err = executeSQL.Error

	return
}

// INSERT INTO @@table (columns) VALUES (values...)
func (s scrapingJobORMDo) CreateInBatch(items []lead_scraper_servicev1.ScrapingJobORM, batchSize int) (err error) {
	var generateSQL strings.Builder
	generateSQL.WriteString("INSERT INTO gmaps_jobs (columns) VALUES (values...) ")

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Exec(generateSQL.String()) // ignore_security_alert
	err = executeSQL.Error

	return
}

// DELETE FROM @@table
// {{where}}
//
//	id IN (@ids)
//
// {{end}}
func (s scrapingJobORMDo) DeleteInBatch(ids []uint64) (err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("DELETE FROM gmaps_jobs ")
	var whereSQL0 strings.Builder
	params = append(params, ids)
	whereSQL0.WriteString("id IN (?) ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Exec(generateSQL.String(), params...) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// {{where}}
//
//	created_at BETWEEN @startTime AND @endTime
//
// {{end}}
func (s scrapingJobORMDo) GetByTimeRange(startTime time.Time, endTime time.Time) (result []lead_scraper_servicev1.ScrapingJobORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM gmaps_jobs ")
	var whereSQL0 strings.Builder
	params = append(params, startTime)
	params = append(params, endTime)
	whereSQL0.WriteString("created_at BETWEEN ? AND ? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// {{where}}
//
//	column_name @operator @value
//
// {{end}}
func (s scrapingJobORMDo) FindBy(columnName string, operator string, value interface{}) (result []lead_scraper_servicev1.ScrapingJobORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM gmaps_jobs ")
	var whereSQL0 strings.Builder
	params = append(params, operator)
	params = append(params, value)
	whereSQL0.WriteString("column_name ?? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// {{where}}
//
//	column_name LIKE @pattern
//
// {{end}}
func (s scrapingJobORMDo) FindByPattern(columnName string, pattern string) (result []lead_scraper_servicev1.ScrapingJobORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM gmaps_jobs ")
	var whereSQL0 strings.Builder
	params = append(params, pattern)
	whereSQL0.WriteString("column_name LIKE ? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT DISTINCT column_name FROM @@table
func (s scrapingJobORMDo) GetDistinct(columnName string) (result []lead_scraper_servicev1.ScrapingJobORM, err error) {
	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT DISTINCT column_name FROM gmaps_jobs ")

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String()).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// {{where}}
//
//	@conditions
//
// {{end}}
// ORDER BY @orderBy
// LIMIT @limit OFFSET @offset
func (s scrapingJobORMDo) FindWithFilters(conditions map[string]interface{}, orderBy string, limit int, offset int) (result []lead_scraper_servicev1.ScrapingJobORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM gmaps_jobs ")
	var whereSQL0 strings.Builder
	params = append(params, conditions)
	whereSQL0.WriteString("? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)
	params = append(params, orderBy)
	params = append(params, limit)
	params = append(params, offset)
	generateSQL.WriteString("ORDER BY ? LIMIT ? OFFSET ? ")

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// UPDATE @@table SET updated_at=CURRENT_TIMESTAMP
// {{where}}
//
//	id=@id
//
// {{end}}
func (s scrapingJobORMDo) Touch(id uint64) (err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("UPDATE gmaps_jobs SET updated_at=CURRENT_TIMESTAMP ")
	var whereSQL0 strings.Builder
	params = append(params, id)
	whereSQL0.WriteString("id=? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Exec(generateSQL.String(), params...) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT EXISTS(
//
//	SELECT 1 FROM @@table
//	 {{where}}
//	     @column = @value
//	 {{end}}
//
// )
func (s scrapingJobORMDo) Exists(column string, value interface{}) (result bool, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT EXISTS( SELECT 1 FROM gmaps_jobs ")
	var whereSQL0 strings.Builder
	params = append(params, column)
	params = append(params, value)
	whereSQL0.WriteString("? = ? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)
	generateSQL.WriteString(") ")

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Take(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT EXISTS(
//
//	SELECT 1 FROM @@table
//	 {{where}}
//	     id = @id
//	 {{end}}
//
// )
func (s scrapingJobORMDo) ExistsById(id uint64) (result bool, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT EXISTS( SELECT 1 FROM gmaps_jobs ")
	var whereSQL0 strings.Builder
	params = append(params, id)
	whereSQL0.WriteString("id = ? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)
	generateSQL.WriteString(") ")

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Take(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// {{where}}
//
//	@column IN (SELECT @foreignKey FROM @foreignTable)
//
// {{end}}
func (s scrapingJobORMDo) FindBySubquery(column string, foreignTable string, foreignKey string) (result []lead_scraper_servicev1.ScrapingJobORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM gmaps_jobs ")
	var whereSQL0 strings.Builder
	params = append(params, column)
	params = append(params, foreignKey)
	params = append(params, foreignTable)
	whereSQL0.WriteString("? IN (SELECT ? FROM ?) ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT EXISTS(
//
//	SELECT 1 FROM @@table
//	 {{where}}
//	     @column = @value
//	 {{end}}
//
// ), COALESCE((
//
//	SELECT @column FROM @@table
//	 {{where}}
//	     @column = @value
//	 {{end}}
//	LIMIT 1
//
// ), NULL)
func (s scrapingJobORMDo) ExistsAndGet(column string, value interface{}) (result lead_scraper_servicev1.ScrapingJobORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT EXISTS( SELECT 1 FROM gmaps_jobs ")
	var whereSQL0 strings.Builder
	params = append(params, column)
	params = append(params, value)
	whereSQL0.WriteString("? = ? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)
	params = append(params, column)
	generateSQL.WriteString("), COALESCE(( SELECT ? FROM gmaps_jobs ")
	var whereSQL1 strings.Builder
	params = append(params, column)
	params = append(params, value)
	whereSQL1.WriteString("? = ? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL1)
	generateSQL.WriteString("LIMIT 1 ), NULL) ")

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Take(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT EXISTS(
//
//	SELECT 1 FROM @@table
//	 {{where}}
//	     @column = @value AND deleted_at IS NULL
//	 {{end}}
//
// ), COALESCE((
//
//	SELECT @column FROM @@table
//	 {{where}}
//	     @column = @value AND deleted_at IS NULL
//	 {{end}}
//	LIMIT 1
//
// ), NULL)
func (s scrapingJobORMDo) ExistsAndGetActive(column string, value interface{}) (result lead_scraper_servicev1.ScrapingJobORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT EXISTS( SELECT 1 FROM gmaps_jobs ")
	var whereSQL0 strings.Builder
	params = append(params, column)
	params = append(params, value)
	whereSQL0.WriteString("? = ? AND deleted_at IS NULL ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)
	params = append(params, column)
	generateSQL.WriteString("), COALESCE(( SELECT ? FROM gmaps_jobs ")
	var whereSQL1 strings.Builder
	params = append(params, column)
	params = append(params, value)
	whereSQL1.WriteString("? = ? AND deleted_at IS NULL ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL1)
	generateSQL.WriteString("LIMIT 1 ), NULL) ")

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Take(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

func (s scrapingJobORMDo) Debug() IScrapingJobORMDo {
	return s.withDO(s.DO.Debug())
}

func (s scrapingJobORMDo) WithContext(ctx context.Context) IScrapingJobORMDo {
	return s.withDO(s.DO.WithContext(ctx))
}

func (s scrapingJobORMDo) ReadDB() IScrapingJobORMDo {
	return s.Clauses(dbresolver.Read)
}

func (s scrapingJobORMDo) WriteDB() IScrapingJobORMDo {
	return s.Clauses(dbresolver.Write)
}

func (s scrapingJobORMDo) Session(config *gorm.Session) IScrapingJobORMDo {
	return s.withDO(s.DO.Session(config))
}

func (s scrapingJobORMDo) Clauses(conds ...clause.Expression) IScrapingJobORMDo {
	return s.withDO(s.DO.Clauses(conds...))
}

func (s scrapingJobORMDo) Returning(value interface{}, columns ...string) IScrapingJobORMDo {
	return s.withDO(s.DO.Returning(value, columns...))
}

func (s scrapingJobORMDo) Not(conds ...gen.Condition) IScrapingJobORMDo {
	return s.withDO(s.DO.Not(conds...))
}

func (s scrapingJobORMDo) Or(conds ...gen.Condition) IScrapingJobORMDo {
	return s.withDO(s.DO.Or(conds...))
}

func (s scrapingJobORMDo) Select(conds ...field.Expr) IScrapingJobORMDo {
	return s.withDO(s.DO.Select(conds...))
}

func (s scrapingJobORMDo) Where(conds ...gen.Condition) IScrapingJobORMDo {
	return s.withDO(s.DO.Where(conds...))
}

func (s scrapingJobORMDo) Order(conds ...field.Expr) IScrapingJobORMDo {
	return s.withDO(s.DO.Order(conds...))
}

func (s scrapingJobORMDo) Distinct(cols ...field.Expr) IScrapingJobORMDo {
	return s.withDO(s.DO.Distinct(cols...))
}

func (s scrapingJobORMDo) Omit(cols ...field.Expr) IScrapingJobORMDo {
	return s.withDO(s.DO.Omit(cols...))
}

func (s scrapingJobORMDo) Join(table schema.Tabler, on ...field.Expr) IScrapingJobORMDo {
	return s.withDO(s.DO.Join(table, on...))
}

func (s scrapingJobORMDo) LeftJoin(table schema.Tabler, on ...field.Expr) IScrapingJobORMDo {
	return s.withDO(s.DO.LeftJoin(table, on...))
}

func (s scrapingJobORMDo) RightJoin(table schema.Tabler, on ...field.Expr) IScrapingJobORMDo {
	return s.withDO(s.DO.RightJoin(table, on...))
}

func (s scrapingJobORMDo) Group(cols ...field.Expr) IScrapingJobORMDo {
	return s.withDO(s.DO.Group(cols...))
}

func (s scrapingJobORMDo) Having(conds ...gen.Condition) IScrapingJobORMDo {
	return s.withDO(s.DO.Having(conds...))
}

func (s scrapingJobORMDo) Limit(limit int) IScrapingJobORMDo {
	return s.withDO(s.DO.Limit(limit))
}

func (s scrapingJobORMDo) Offset(offset int) IScrapingJobORMDo {
	return s.withDO(s.DO.Offset(offset))
}

func (s scrapingJobORMDo) Scopes(funcs ...func(gen.Dao) gen.Dao) IScrapingJobORMDo {
	return s.withDO(s.DO.Scopes(funcs...))
}

func (s scrapingJobORMDo) Unscoped() IScrapingJobORMDo {
	return s.withDO(s.DO.Unscoped())
}

func (s scrapingJobORMDo) Create(values ...*lead_scraper_servicev1.ScrapingJobORM) error {
	if len(values) == 0 {
		return nil
	}
	return s.DO.Create(values)
}

func (s scrapingJobORMDo) CreateInBatches(values []*lead_scraper_servicev1.ScrapingJobORM, batchSize int) error {
	return s.DO.CreateInBatches(values, batchSize)
}

// Save : !!! underlying implementation is different with GORM
// The method is equivalent to executing the statement: db.Clauses(clause.OnConflict{UpdateAll: true}).Create(values)
func (s scrapingJobORMDo) Save(values ...*lead_scraper_servicev1.ScrapingJobORM) error {
	if len(values) == 0 {
		return nil
	}
	return s.DO.Save(values)
}

func (s scrapingJobORMDo) First() (*lead_scraper_servicev1.ScrapingJobORM, error) {
	if result, err := s.DO.First(); err != nil {
		return nil, err
	} else {
		return result.(*lead_scraper_servicev1.ScrapingJobORM), nil
	}
}

func (s scrapingJobORMDo) Take() (*lead_scraper_servicev1.ScrapingJobORM, error) {
	if result, err := s.DO.Take(); err != nil {
		return nil, err
	} else {
		return result.(*lead_scraper_servicev1.ScrapingJobORM), nil
	}
}

func (s scrapingJobORMDo) Last() (*lead_scraper_servicev1.ScrapingJobORM, error) {
	if result, err := s.DO.Last(); err != nil {
		return nil, err
	} else {
		return result.(*lead_scraper_servicev1.ScrapingJobORM), nil
	}
}

func (s scrapingJobORMDo) Find() ([]*lead_scraper_servicev1.ScrapingJobORM, error) {
	result, err := s.DO.Find()
	return result.([]*lead_scraper_servicev1.ScrapingJobORM), err
}

func (s scrapingJobORMDo) FindInBatch(batchSize int, fc func(tx gen.Dao, batch int) error) (results []*lead_scraper_servicev1.ScrapingJobORM, err error) {
	buf := make([]*lead_scraper_servicev1.ScrapingJobORM, 0, batchSize)
	err = s.DO.FindInBatches(&buf, batchSize, func(tx gen.Dao, batch int) error {
		defer func() { results = append(results, buf...) }()
		return fc(tx, batch)
	})
	return results, err
}

func (s scrapingJobORMDo) FindInBatches(result *[]*lead_scraper_servicev1.ScrapingJobORM, batchSize int, fc func(tx gen.Dao, batch int) error) error {
	return s.DO.FindInBatches(result, batchSize, fc)
}

func (s scrapingJobORMDo) Attrs(attrs ...field.AssignExpr) IScrapingJobORMDo {
	return s.withDO(s.DO.Attrs(attrs...))
}

func (s scrapingJobORMDo) Assign(attrs ...field.AssignExpr) IScrapingJobORMDo {
	return s.withDO(s.DO.Assign(attrs...))
}

func (s scrapingJobORMDo) Joins(fields ...field.RelationField) IScrapingJobORMDo {
	for _, _f := range fields {
		s = *s.withDO(s.DO.Joins(_f))
	}
	return &s
}

func (s scrapingJobORMDo) Preload(fields ...field.RelationField) IScrapingJobORMDo {
	for _, _f := range fields {
		s = *s.withDO(s.DO.Preload(_f))
	}
	return &s
}

func (s scrapingJobORMDo) FirstOrInit() (*lead_scraper_servicev1.ScrapingJobORM, error) {
	if result, err := s.DO.FirstOrInit(); err != nil {
		return nil, err
	} else {
		return result.(*lead_scraper_servicev1.ScrapingJobORM), nil
	}
}

func (s scrapingJobORMDo) FirstOrCreate() (*lead_scraper_servicev1.ScrapingJobORM, error) {
	if result, err := s.DO.FirstOrCreate(); err != nil {
		return nil, err
	} else {
		return result.(*lead_scraper_servicev1.ScrapingJobORM), nil
	}
}

func (s scrapingJobORMDo) FindByPage(offset int, limit int) (result []*lead_scraper_servicev1.ScrapingJobORM, count int64, err error) {
	result, err = s.Offset(offset).Limit(limit).Find()
	if err != nil {
		return
	}

	if size := len(result); 0 < limit && 0 < size && size < limit {
		count = int64(size + offset)
		return
	}

	count, err = s.Offset(-1).Limit(-1).Count()
	return
}

func (s scrapingJobORMDo) ScanByPage(result interface{}, offset int, limit int) (count int64, err error) {
	count, err = s.Count()
	if err != nil {
		return
	}

	err = s.Offset(offset).Limit(limit).Scan(result)
	return
}

func (s scrapingJobORMDo) Scan(result interface{}) (err error) {
	return s.DO.Scan(result)
}

func (s scrapingJobORMDo) Delete(models ...*lead_scraper_servicev1.ScrapingJobORM) (result gen.ResultInfo, err error) {
	return s.DO.Delete(models)
}

func (s *scrapingJobORMDo) withDO(do gen.Dao) *scrapingJobORMDo {
	s.DO = *do.(*gen.DO)
	return s
}
