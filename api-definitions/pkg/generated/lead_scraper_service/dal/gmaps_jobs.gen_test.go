// Code generated by gorm.io/gen. DO NOT EDIT.
// Code generated by gorm.io/gen. DO NOT EDIT.
// Code generated by gorm.io/gen. DO NOT EDIT.

package dal

import (
	"context"
	"fmt"
	"strconv"
	"testing"
	"time"

	lead_scraper_servicev1 "github.com/VectorEngineering/vector-protobuf-definitions/api-definitions/pkg/generated/lead_scraper_service/v1"
	"gorm.io/gen"
	"gorm.io/gen/field"
	"gorm.io/gorm/clause"
)

func init() {
	InitializeDB()
	err := _gen_test_db.AutoMigrate(&lead_scraper_servicev1.ScrapingJobORM{})
	if err != nil {
		fmt.Printf("Error: AutoMigrate(&lead_scraper_servicev1.ScrapingJobORM{}) fail: %s", err)
	}
}

func Test_scrapingJobORMQuery(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	scrapingJobORM = *scrapingJobORM.As(scrapingJobORM.TableName())
	_do := scrapingJobORM.WithContext(context.Background()).Debug()

	primaryKey := field.NewString(scrapingJobORM.TableName(), clause.PrimaryKey)
	_, err := _do.Unscoped().Where(primaryKey.IsNotNull()).Delete()
	if err != nil {
		t.Error("clean table <gmaps_jobs> fail:", err)
		return
	}

	_, ok := scrapingJobORM.GetFieldByName("")
	if ok {
		t.Error("GetFieldByName(\"\") from scrapingJobORM success")
	}

	err = _do.Create(&lead_scraper_servicev1.ScrapingJobORM{})
	if err != nil {
		t.Error("create item in table <gmaps_jobs> fail:", err)
	}

	err = _do.Save(&lead_scraper_servicev1.ScrapingJobORM{})
	if err != nil {
		t.Error("create item in table <gmaps_jobs> fail:", err)
	}

	err = _do.CreateInBatches([]*lead_scraper_servicev1.ScrapingJobORM{{}, {}}, 10)
	if err != nil {
		t.Error("create item in table <gmaps_jobs> fail:", err)
	}

	_, err = _do.Select(scrapingJobORM.ALL).Take()
	if err != nil {
		t.Error("Take() on table <gmaps_jobs> fail:", err)
	}

	_, err = _do.First()
	if err != nil {
		t.Error("First() on table <gmaps_jobs> fail:", err)
	}

	_, err = _do.Last()
	if err != nil {
		t.Error("First() on table <gmaps_jobs> fail:", err)
	}

	_, err = _do.Where(primaryKey.IsNotNull()).FindInBatch(10, func(tx gen.Dao, batch int) error { return nil })
	if err != nil {
		t.Error("FindInBatch() on table <gmaps_jobs> fail:", err)
	}

	err = _do.Where(primaryKey.IsNotNull()).FindInBatches(&[]*lead_scraper_servicev1.ScrapingJobORM{}, 10, func(tx gen.Dao, batch int) error { return nil })
	if err != nil {
		t.Error("FindInBatches() on table <gmaps_jobs> fail:", err)
	}

	_, err = _do.Select(scrapingJobORM.ALL).Where(primaryKey.IsNotNull()).Order(primaryKey.Desc()).Find()
	if err != nil {
		t.Error("Find() on table <gmaps_jobs> fail:", err)
	}

	_, err = _do.Distinct(primaryKey).Take()
	if err != nil {
		t.Error("select Distinct() on table <gmaps_jobs> fail:", err)
	}

	_, err = _do.Select(scrapingJobORM.ALL).Omit(primaryKey).Take()
	if err != nil {
		t.Error("Omit() on table <gmaps_jobs> fail:", err)
	}

	_, err = _do.Group(primaryKey).Find()
	if err != nil {
		t.Error("Group() on table <gmaps_jobs> fail:", err)
	}

	_, err = _do.Scopes(func(dao gen.Dao) gen.Dao { return dao.Where(primaryKey.IsNotNull()) }).Find()
	if err != nil {
		t.Error("Scopes() on table <gmaps_jobs> fail:", err)
	}

	_, _, err = _do.FindByPage(0, 1)
	if err != nil {
		t.Error("FindByPage() on table <gmaps_jobs> fail:", err)
	}

	_, err = _do.ScanByPage(&lead_scraper_servicev1.ScrapingJobORM{}, 0, 1)
	if err != nil {
		t.Error("ScanByPage() on table <gmaps_jobs> fail:", err)
	}

	_, err = _do.Attrs(primaryKey).Assign(primaryKey).FirstOrInit()
	if err != nil {
		t.Error("FirstOrInit() on table <gmaps_jobs> fail:", err)
	}

	_, err = _do.Attrs(primaryKey).Assign(primaryKey).FirstOrCreate()
	if err != nil {
		t.Error("FirstOrCreate() on table <gmaps_jobs> fail:", err)
	}

	var _a _another
	var _aPK = field.NewString(_a.TableName(), "id")

	err = _do.Join(&_a, primaryKey.EqCol(_aPK)).Scan(map[string]interface{}{})
	if err != nil {
		t.Error("Join() on table <gmaps_jobs> fail:", err)
	}

	err = _do.LeftJoin(&_a, primaryKey.EqCol(_aPK)).Scan(map[string]interface{}{})
	if err != nil {
		t.Error("LeftJoin() on table <gmaps_jobs> fail:", err)
	}

	_, err = _do.Not().Or().Clauses().Take()
	if err != nil {
		t.Error("Not/Or/Clauses on table <gmaps_jobs> fail:", err)
	}
}

var ScrapingJobORMGetRecordByIDTestCase = []TestCase{}

func Test_scrapingJobORM_GetRecordByID(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMGetRecordByIDTestCase {
		t.Run("GetRecordByID_"+strconv.Itoa(i), func(t *testing.T) {
			res1, res2 := do.GetRecordByID(tt.Input.Args[0].(uint64))
			assert(t, "GetRecordByID", res1, tt.Expectation.Ret[0])
			assert(t, "GetRecordByID", res2, tt.Expectation.Ret[1])
		})
	}
}

var ScrapingJobORMGetRecordByIDsTestCase = []TestCase{}

func Test_scrapingJobORM_GetRecordByIDs(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMGetRecordByIDsTestCase {
		t.Run("GetRecordByIDs_"+strconv.Itoa(i), func(t *testing.T) {
			res1, res2 := do.GetRecordByIDs(tt.Input.Args[0].([]uint64))
			assert(t, "GetRecordByIDs", res1, tt.Expectation.Ret[0])
			assert(t, "GetRecordByIDs", res2, tt.Expectation.Ret[1])
		})
	}
}

var ScrapingJobORMDeleteRecordByIDTestCase = []TestCase{}

func Test_scrapingJobORM_DeleteRecordByID(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMDeleteRecordByIDTestCase {
		t.Run("DeleteRecordByID_"+strconv.Itoa(i), func(t *testing.T) {
			res1 := do.DeleteRecordByID(tt.Input.Args[0].(uint64))
			assert(t, "DeleteRecordByID", res1, tt.Expectation.Ret[0])
		})
	}
}

var ScrapingJobORMGetAllRecordsTestCase = []TestCase{}

func Test_scrapingJobORM_GetAllRecords(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMGetAllRecordsTestCase {
		t.Run("GetAllRecords_"+strconv.Itoa(i), func(t *testing.T) {
			res1, res2 := do.GetAllRecords(tt.Input.Args[0].(string), tt.Input.Args[1].(int), tt.Input.Args[2].(int))
			assert(t, "GetAllRecords", res1, tt.Expectation.Ret[0])
			assert(t, "GetAllRecords", res2, tt.Expectation.Ret[1])
		})
	}
}

var ScrapingJobORMCountAllTestCase = []TestCase{}

func Test_scrapingJobORM_CountAll(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMCountAllTestCase {
		t.Run("CountAll_"+strconv.Itoa(i), func(t *testing.T) {
			res1, res2 := do.CountAll()
			assert(t, "CountAll", res1, tt.Expectation.Ret[0])
			assert(t, "CountAll", res2, tt.Expectation.Ret[1])
		})
	}
}

var ScrapingJobORMGetByIDTestCase = []TestCase{}

func Test_scrapingJobORM_GetByID(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMGetByIDTestCase {
		t.Run("GetByID_"+strconv.Itoa(i), func(t *testing.T) {
			res1, res2 := do.GetByID(tt.Input.Args[0].(uint64))
			assert(t, "GetByID", res1, tt.Expectation.Ret[0])
			assert(t, "GetByID", res2, tt.Expectation.Ret[1])
		})
	}
}

var ScrapingJobORMGetByIDsTestCase = []TestCase{}

func Test_scrapingJobORM_GetByIDs(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMGetByIDsTestCase {
		t.Run("GetByIDs_"+strconv.Itoa(i), func(t *testing.T) {
			res1, res2 := do.GetByIDs(tt.Input.Args[0].([]uint64))
			assert(t, "GetByIDs", res1, tt.Expectation.Ret[0])
			assert(t, "GetByIDs", res2, tt.Expectation.Ret[1])
		})
	}
}

var ScrapingJobORMGetActivePaginatedTestCase = []TestCase{}

func Test_scrapingJobORM_GetActivePaginated(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMGetActivePaginatedTestCase {
		t.Run("GetActivePaginated_"+strconv.Itoa(i), func(t *testing.T) {
			res1, res2 := do.GetActivePaginated(tt.Input.Args[0].(string), tt.Input.Args[1].(int), tt.Input.Args[2].(int))
			assert(t, "GetActivePaginated", res1, tt.Expectation.Ret[0])
			assert(t, "GetActivePaginated", res2, tt.Expectation.Ret[1])
		})
	}
}

var ScrapingJobORMGetDeletedTestCase = []TestCase{}

func Test_scrapingJobORM_GetDeleted(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMGetDeletedTestCase {
		t.Run("GetDeleted_"+strconv.Itoa(i), func(t *testing.T) {
			res1, res2 := do.GetDeleted()
			assert(t, "GetDeleted", res1, tt.Expectation.Ret[0])
			assert(t, "GetDeleted", res2, tt.Expectation.Ret[1])
		})
	}
}

var ScrapingJobORMSoftDeleteTestCase = []TestCase{}

func Test_scrapingJobORM_SoftDelete(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMSoftDeleteTestCase {
		t.Run("SoftDelete_"+strconv.Itoa(i), func(t *testing.T) {
			res1 := do.SoftDelete(tt.Input.Args[0].(uint64))
			assert(t, "SoftDelete", res1, tt.Expectation.Ret[0])
		})
	}
}

var ScrapingJobORMRestoreTestCase = []TestCase{}

func Test_scrapingJobORM_Restore(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMRestoreTestCase {
		t.Run("Restore_"+strconv.Itoa(i), func(t *testing.T) {
			res1 := do.Restore(tt.Input.Args[0].(uint64))
			assert(t, "Restore", res1, tt.Expectation.Ret[0])
		})
	}
}

var ScrapingJobORMDeleteInBatchTestCase = []TestCase{}

func Test_scrapingJobORM_DeleteInBatch(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMDeleteInBatchTestCase {
		t.Run("DeleteInBatch_"+strconv.Itoa(i), func(t *testing.T) {
			res1 := do.DeleteInBatch(tt.Input.Args[0].([]uint64), tt.Input.Args[1].(int))
			assert(t, "DeleteInBatch", res1, tt.Expectation.Ret[0])
		})
	}
}

var ScrapingJobORMGetByTimeRangeTestCase = []TestCase{}

func Test_scrapingJobORM_GetByTimeRange(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMGetByTimeRangeTestCase {
		t.Run("GetByTimeRange_"+strconv.Itoa(i), func(t *testing.T) {
			res1, res2 := do.GetByTimeRange(tt.Input.Args[0].(time.Time), tt.Input.Args[1].(time.Time))
			assert(t, "GetByTimeRange", res1, tt.Expectation.Ret[0])
			assert(t, "GetByTimeRange", res2, tt.Expectation.Ret[1])
		})
	}
}

var ScrapingJobORMFindByTestCase = []TestCase{}

func Test_scrapingJobORM_FindBy(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMFindByTestCase {
		t.Run("FindBy_"+strconv.Itoa(i), func(t *testing.T) {
			res1, res2 := do.FindBy(tt.Input.Args[0].(string), tt.Input.Args[1].(string), tt.Input.Args[2].(interface{}))
			assert(t, "FindBy", res1, tt.Expectation.Ret[0])
			assert(t, "FindBy", res2, tt.Expectation.Ret[1])
		})
	}
}

var ScrapingJobORMFindByPatternTestCase = []TestCase{}

func Test_scrapingJobORM_FindByPattern(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMFindByPatternTestCase {
		t.Run("FindByPattern_"+strconv.Itoa(i), func(t *testing.T) {
			res1, res2 := do.FindByPattern(tt.Input.Args[0].(string), tt.Input.Args[1].(string))
			assert(t, "FindByPattern", res1, tt.Expectation.Ret[0])
			assert(t, "FindByPattern", res2, tt.Expectation.Ret[1])
		})
	}
}

var ScrapingJobORMGetDistinctTestCase = []TestCase{}

func Test_scrapingJobORM_GetDistinct(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMGetDistinctTestCase {
		t.Run("GetDistinct_"+strconv.Itoa(i), func(t *testing.T) {
			res1, res2 := do.GetDistinct(tt.Input.Args[0].(string))
			assert(t, "GetDistinct", res1, tt.Expectation.Ret[0])
			assert(t, "GetDistinct", res2, tt.Expectation.Ret[1])
		})
	}
}

var ScrapingJobORMFindWithFiltersTestCase = []TestCase{}

func Test_scrapingJobORM_FindWithFilters(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMFindWithFiltersTestCase {
		t.Run("FindWithFilters_"+strconv.Itoa(i), func(t *testing.T) {
			res1, res2 := do.FindWithFilters(tt.Input.Args[0].(map[string]interface{}), tt.Input.Args[1].(string), tt.Input.Args[2].(int), tt.Input.Args[3].(int))
			assert(t, "FindWithFilters", res1, tt.Expectation.Ret[0])
			assert(t, "FindWithFilters", res2, tt.Expectation.Ret[1])
		})
	}
}

var ScrapingJobORMTouchTestCase = []TestCase{}

func Test_scrapingJobORM_Touch(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMTouchTestCase {
		t.Run("Touch_"+strconv.Itoa(i), func(t *testing.T) {
			res1 := do.Touch(tt.Input.Args[0].(uint64))
			assert(t, "Touch", res1, tt.Expectation.Ret[0])
		})
	}
}

var ScrapingJobORMExistsTestCase = []TestCase{}

func Test_scrapingJobORM_Exists(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMExistsTestCase {
		t.Run("Exists_"+strconv.Itoa(i), func(t *testing.T) {
			res1, res2 := do.Exists(tt.Input.Args[0].(string), tt.Input.Args[1].(interface{}))
			assert(t, "Exists", res1, tt.Expectation.Ret[0])
			assert(t, "Exists", res2, tt.Expectation.Ret[1])
		})
	}
}

var ScrapingJobORMExistsByIdTestCase = []TestCase{}

func Test_scrapingJobORM_ExistsById(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMExistsByIdTestCase {
		t.Run("ExistsById_"+strconv.Itoa(i), func(t *testing.T) {
			res1, res2 := do.ExistsById(tt.Input.Args[0].(uint64))
			assert(t, "ExistsById", res1, tt.Expectation.Ret[0])
			assert(t, "ExistsById", res2, tt.Expectation.Ret[1])
		})
	}
}

var ScrapingJobORMFindBySubqueryTestCase = []TestCase{}

func Test_scrapingJobORM_FindBySubquery(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMFindBySubqueryTestCase {
		t.Run("FindBySubquery_"+strconv.Itoa(i), func(t *testing.T) {
			res1, res2 := do.FindBySubquery(tt.Input.Args[0].(string), tt.Input.Args[1].(string), tt.Input.Args[2].(string))
			assert(t, "FindBySubquery", res1, tt.Expectation.Ret[0])
			assert(t, "FindBySubquery", res2, tt.Expectation.Ret[1])
		})
	}
}

var ScrapingJobORMExistsAndGetTestCase = []TestCase{}

func Test_scrapingJobORM_ExistsAndGet(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMExistsAndGetTestCase {
		t.Run("ExistsAndGet_"+strconv.Itoa(i), func(t *testing.T) {
			res1, res2 := do.ExistsAndGet(tt.Input.Args[0].(string), tt.Input.Args[1].(interface{}))
			assert(t, "ExistsAndGet", res1, tt.Expectation.Ret[0])
			assert(t, "ExistsAndGet", res2, tt.Expectation.Ret[1])
		})
	}
}

var ScrapingJobORMExistsAndGetActiveTestCase = []TestCase{}

func Test_scrapingJobORM_ExistsAndGetActive(t *testing.T) {
	scrapingJobORM := newScrapingJobORM(_gen_test_db)
	do := scrapingJobORM.WithContext(context.Background()).Debug()

	for i, tt := range ScrapingJobORMExistsAndGetActiveTestCase {
		t.Run("ExistsAndGetActive_"+strconv.Itoa(i), func(t *testing.T) {
			res1, res2 := do.ExistsAndGetActive(tt.Input.Args[0].(string), tt.Input.Args[1].(interface{}))
			assert(t, "ExistsAndGetActive", res1, tt.Expectation.Ret[0])
			assert(t, "ExistsAndGetActive", res2, tt.Expectation.Ret[1])
		})
	}
}
