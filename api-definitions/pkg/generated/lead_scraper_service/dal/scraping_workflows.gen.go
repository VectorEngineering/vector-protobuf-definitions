// Code generated by gorm.io/gen. DO NOT EDIT.
// Code generated by gorm.io/gen. DO NOT EDIT.
// Code generated by gorm.io/gen. DO NOT EDIT.

package dal

import (
	"context"
	"strings"

	lead_scraper_servicev1 "github.com/Vector/vector-protobuf-definitions/api-definitions/pkg/generated/lead_scraper_service/v1"
	"gorm.io/gorm"
	"gorm.io/gorm/clause"
	"gorm.io/gorm/schema"

	"gorm.io/gen"
	"gorm.io/gen/field"
	"gorm.io/gen/helper"

	"gorm.io/plugin/dbresolver"

	"time"
)

func newScrapingWorkflowORM(db *gorm.DB, opts ...gen.DOOption) scrapingWorkflowORM {
	_scrapingWorkflowORM := scrapingWorkflowORM{}

	_scrapingWorkflowORM.scrapingWorkflowORMDo.UseDB(db, opts...)
	_scrapingWorkflowORM.scrapingWorkflowORMDo.UseModel(&lead_scraper_servicev1.ScrapingWorkflowORM{})

	tableName := _scrapingWorkflowORM.scrapingWorkflowORMDo.TableName()
	_scrapingWorkflowORM.ALL = field.NewAsterisk(tableName)
	_scrapingWorkflowORM.AcceptTermsOfService = field.NewBool(tableName, "accept_terms_of_service")
	_scrapingWorkflowORM.AlertEmails = field.NewString(tableName, "alert_emails")
	_scrapingWorkflowORM.AnonymizePii = field.NewBool(tableName, "anonymize_pii")
	_scrapingWorkflowORM.ContentFilterAllowedCountries = field.NewField(tableName, "content_filter_allowed_countries")
	_scrapingWorkflowORM.ContentFilterExcludedTypes = field.NewField(tableName, "content_filter_excluded_types")
	_scrapingWorkflowORM.ContentFilterMinimumRating = field.NewFloat32(tableName, "content_filter_minimum_rating")
	_scrapingWorkflowORM.ContentFilterMinimumReviews = field.NewInt32(tableName, "content_filter_minimum_reviews")
	_scrapingWorkflowORM.CreatedAt = field.NewTime(tableName, "created_at")
	_scrapingWorkflowORM.CronExpression = field.NewString(tableName, "cron_expression")
	_scrapingWorkflowORM.DataRetention = field.NewInt64(tableName, "data_retention")
	_scrapingWorkflowORM.DeletedAt = field.NewTime(tableName, "deleted_at")
	_scrapingWorkflowORM.GeoFencingLat = field.NewFloat64(tableName, "geo_fencing_lat")
	_scrapingWorkflowORM.GeoFencingLon = field.NewFloat64(tableName, "geo_fencing_lon")
	_scrapingWorkflowORM.GeoFencingRadius = field.NewFloat32(tableName, "geo_fencing_radius")
	_scrapingWorkflowORM.GeoFencingZoomMax = field.NewInt32(tableName, "geo_fencing_zoom_max")
	_scrapingWorkflowORM.GeoFencingZoomMin = field.NewInt32(tableName, "geo_fencing_zoom_min")
	_scrapingWorkflowORM.Id = field.NewUint64(tableName, "id")
	_scrapingWorkflowORM.IncludeBusinessHours = field.NewBool(tableName, "include_business_hours")
	_scrapingWorkflowORM.IncludePhotos = field.NewBool(tableName, "include_photos")
	_scrapingWorkflowORM.IncludeReviews = field.NewBool(tableName, "include_reviews")
	_scrapingWorkflowORM.LastRunTime = field.NewTime(tableName, "last_run_time")
	_scrapingWorkflowORM.MaxRetries = field.NewInt32(tableName, "max_retries")
	_scrapingWorkflowORM.MaxReviewsPerBusiness = field.NewInt32(tableName, "max_reviews_per_business")
	_scrapingWorkflowORM.NextRunTime = field.NewTime(tableName, "next_run_time")
	_scrapingWorkflowORM.NotificationEmailGroup = field.NewString(tableName, "notification_email_group")
	_scrapingWorkflowORM.NotificationNotifyOnComplete = field.NewBool(tableName, "notification_notify_on_complete")
	_scrapingWorkflowORM.NotificationNotifyOnFailure = field.NewBool(tableName, "notification_notify_on_failure")
	_scrapingWorkflowORM.NotificationNotifyOnStart = field.NewBool(tableName, "notification_notify_on_start")
	_scrapingWorkflowORM.NotificationSlackChannel = field.NewString(tableName, "notification_slack_channel")
	_scrapingWorkflowORM.NotificationWebhookUrl = field.NewString(tableName, "notification_webhook_url")
	_scrapingWorkflowORM.OrgId = field.NewString(tableName, "org_id")
	_scrapingWorkflowORM.OutputDestination = field.NewString(tableName, "output_destination")
	_scrapingWorkflowORM.OutputFormat = field.NewString(tableName, "output_format")
	_scrapingWorkflowORM.QosEnableJavascript = field.NewBool(tableName, "qos_enable_javascript")
	_scrapingWorkflowORM.QosMaxConcurrentRequests = field.NewInt32(tableName, "qos_max_concurrent_requests")
	_scrapingWorkflowORM.QosMaxRetries = field.NewInt32(tableName, "qos_max_retries")
	_scrapingWorkflowORM.QosRequestTimeout = field.NewInt64(tableName, "qos_request_timeout")
	_scrapingWorkflowORM.RespectRobotsTxt = field.NewBool(tableName, "respect_robots_txt")
	_scrapingWorkflowORM.RetryCount = field.NewInt32(tableName, "retry_count")
	_scrapingWorkflowORM.Status = field.NewString(tableName, "status")
	_scrapingWorkflowORM.TenantId = field.NewString(tableName, "tenant_id")
	_scrapingWorkflowORM.UpdatedAt = field.NewTime(tableName, "updated_at")
	_scrapingWorkflowORM.UserAgent = field.NewString(tableName, "user_agent")
	_scrapingWorkflowORM.WorkspaceId = field.NewUint64(tableName, "workspace_id")
	_scrapingWorkflowORM.Jobs = scrapingWorkflowORMHasManyJobs{
		db: db.Session(&gorm.Session{}),

		RelationField: field.NewRelation("Jobs", "lead_scraper_servicev1.ScrapingJobORM"),
		Leads: struct {
			field.RelationField
			Job struct {
				field.RelationField
			}
			Workspace struct {
				field.RelationField
				Workflows struct {
					field.RelationField
					Workspace struct {
						field.RelationField
					}
					Jobs struct {
						field.RelationField
					}
				}
			}
			RegularHours struct {
				field.RelationField
			}
			Reviews struct {
				field.RelationField
			}
			SpecialHours struct {
				field.RelationField
			}
		}{
			RelationField: field.NewRelation("Jobs.Leads", "lead_scraper_servicev1.LeadORM"),
			Job: struct {
				field.RelationField
			}{
				RelationField: field.NewRelation("Jobs.Leads.Job", "lead_scraper_servicev1.ScrapingJobORM"),
			},
			Workspace: struct {
				field.RelationField
				Workflows struct {
					field.RelationField
					Workspace struct {
						field.RelationField
					}
					Jobs struct {
						field.RelationField
					}
				}
			}{
				RelationField: field.NewRelation("Jobs.Leads.Workspace", "lead_scraper_servicev1.WorkspaceORM"),
				Workflows: struct {
					field.RelationField
					Workspace struct {
						field.RelationField
					}
					Jobs struct {
						field.RelationField
					}
				}{
					RelationField: field.NewRelation("Jobs.Leads.Workspace.Workflows", "lead_scraper_servicev1.ScrapingWorkflowORM"),
					Workspace: struct {
						field.RelationField
					}{
						RelationField: field.NewRelation("Jobs.Leads.Workspace.Workflows.Workspace", "lead_scraper_servicev1.WorkspaceORM"),
					},
					Jobs: struct {
						field.RelationField
					}{
						RelationField: field.NewRelation("Jobs.Leads.Workspace.Workflows.Jobs", "lead_scraper_servicev1.ScrapingJobORM"),
					},
				},
			},
			RegularHours: struct {
				field.RelationField
			}{
				RelationField: field.NewRelation("Jobs.Leads.RegularHours", "lead_scraper_servicev1.BusinessHoursORM"),
			},
			Reviews: struct {
				field.RelationField
			}{
				RelationField: field.NewRelation("Jobs.Leads.Reviews", "lead_scraper_servicev1.ReviewORM"),
			},
			SpecialHours: struct {
				field.RelationField
			}{
				RelationField: field.NewRelation("Jobs.Leads.SpecialHours", "lead_scraper_servicev1.BusinessHoursORM"),
			},
		},
	}

	_scrapingWorkflowORM.Workspace = scrapingWorkflowORMBelongsToWorkspace{
		db: db.Session(&gorm.Session{}),

		RelationField: field.NewRelation("Workspace", "lead_scraper_servicev1.WorkspaceORM"),
	}

	_scrapingWorkflowORM.fillFieldMap()

	return _scrapingWorkflowORM
}

type scrapingWorkflowORM struct {
	scrapingWorkflowORMDo

	ALL                           field.Asterisk
	AcceptTermsOfService          field.Bool
	AlertEmails                   field.String
	AnonymizePii                  field.Bool
	ContentFilterAllowedCountries field.Field
	ContentFilterExcludedTypes    field.Field
	ContentFilterMinimumRating    field.Float32
	ContentFilterMinimumReviews   field.Int32
	CreatedAt                     field.Time
	CronExpression                field.String
	DataRetention                 field.Int64
	DeletedAt                     field.Time
	GeoFencingLat                 field.Float64
	GeoFencingLon                 field.Float64
	GeoFencingRadius              field.Float32
	GeoFencingZoomMax             field.Int32
	GeoFencingZoomMin             field.Int32
	Id                            field.Uint64
	IncludeBusinessHours          field.Bool
	IncludePhotos                 field.Bool
	IncludeReviews                field.Bool
	LastRunTime                   field.Time
	MaxRetries                    field.Int32
	MaxReviewsPerBusiness         field.Int32
	NextRunTime                   field.Time
	NotificationEmailGroup        field.String
	NotificationNotifyOnComplete  field.Bool
	NotificationNotifyOnFailure   field.Bool
	NotificationNotifyOnStart     field.Bool
	NotificationSlackChannel      field.String
	NotificationWebhookUrl        field.String
	OrgId                         field.String
	OutputDestination             field.String
	OutputFormat                  field.String
	QosEnableJavascript           field.Bool
	QosMaxConcurrentRequests      field.Int32
	QosMaxRetries                 field.Int32
	QosRequestTimeout             field.Int64
	RespectRobotsTxt              field.Bool
	RetryCount                    field.Int32
	Status                        field.String
	TenantId                      field.String
	UpdatedAt                     field.Time
	UserAgent                     field.String
	WorkspaceId                   field.Uint64
	Jobs                          scrapingWorkflowORMHasManyJobs

	Workspace scrapingWorkflowORMBelongsToWorkspace

	fieldMap map[string]field.Expr
}

func (s scrapingWorkflowORM) Table(newTableName string) *scrapingWorkflowORM {
	s.scrapingWorkflowORMDo.UseTable(newTableName)
	return s.updateTableName(newTableName)
}

func (s scrapingWorkflowORM) As(alias string) *scrapingWorkflowORM {
	s.scrapingWorkflowORMDo.DO = *(s.scrapingWorkflowORMDo.As(alias).(*gen.DO))
	return s.updateTableName(alias)
}

func (s *scrapingWorkflowORM) updateTableName(table string) *scrapingWorkflowORM {
	s.ALL = field.NewAsterisk(table)
	s.AcceptTermsOfService = field.NewBool(table, "accept_terms_of_service")
	s.AlertEmails = field.NewString(table, "alert_emails")
	s.AnonymizePii = field.NewBool(table, "anonymize_pii")
	s.ContentFilterAllowedCountries = field.NewField(table, "content_filter_allowed_countries")
	s.ContentFilterExcludedTypes = field.NewField(table, "content_filter_excluded_types")
	s.ContentFilterMinimumRating = field.NewFloat32(table, "content_filter_minimum_rating")
	s.ContentFilterMinimumReviews = field.NewInt32(table, "content_filter_minimum_reviews")
	s.CreatedAt = field.NewTime(table, "created_at")
	s.CronExpression = field.NewString(table, "cron_expression")
	s.DataRetention = field.NewInt64(table, "data_retention")
	s.DeletedAt = field.NewTime(table, "deleted_at")
	s.GeoFencingLat = field.NewFloat64(table, "geo_fencing_lat")
	s.GeoFencingLon = field.NewFloat64(table, "geo_fencing_lon")
	s.GeoFencingRadius = field.NewFloat32(table, "geo_fencing_radius")
	s.GeoFencingZoomMax = field.NewInt32(table, "geo_fencing_zoom_max")
	s.GeoFencingZoomMin = field.NewInt32(table, "geo_fencing_zoom_min")
	s.Id = field.NewUint64(table, "id")
	s.IncludeBusinessHours = field.NewBool(table, "include_business_hours")
	s.IncludePhotos = field.NewBool(table, "include_photos")
	s.IncludeReviews = field.NewBool(table, "include_reviews")
	s.LastRunTime = field.NewTime(table, "last_run_time")
	s.MaxRetries = field.NewInt32(table, "max_retries")
	s.MaxReviewsPerBusiness = field.NewInt32(table, "max_reviews_per_business")
	s.NextRunTime = field.NewTime(table, "next_run_time")
	s.NotificationEmailGroup = field.NewString(table, "notification_email_group")
	s.NotificationNotifyOnComplete = field.NewBool(table, "notification_notify_on_complete")
	s.NotificationNotifyOnFailure = field.NewBool(table, "notification_notify_on_failure")
	s.NotificationNotifyOnStart = field.NewBool(table, "notification_notify_on_start")
	s.NotificationSlackChannel = field.NewString(table, "notification_slack_channel")
	s.NotificationWebhookUrl = field.NewString(table, "notification_webhook_url")
	s.OrgId = field.NewString(table, "org_id")
	s.OutputDestination = field.NewString(table, "output_destination")
	s.OutputFormat = field.NewString(table, "output_format")
	s.QosEnableJavascript = field.NewBool(table, "qos_enable_javascript")
	s.QosMaxConcurrentRequests = field.NewInt32(table, "qos_max_concurrent_requests")
	s.QosMaxRetries = field.NewInt32(table, "qos_max_retries")
	s.QosRequestTimeout = field.NewInt64(table, "qos_request_timeout")
	s.RespectRobotsTxt = field.NewBool(table, "respect_robots_txt")
	s.RetryCount = field.NewInt32(table, "retry_count")
	s.Status = field.NewString(table, "status")
	s.TenantId = field.NewString(table, "tenant_id")
	s.UpdatedAt = field.NewTime(table, "updated_at")
	s.UserAgent = field.NewString(table, "user_agent")
	s.WorkspaceId = field.NewUint64(table, "workspace_id")

	s.fillFieldMap()

	return s
}

func (s *scrapingWorkflowORM) GetFieldByName(fieldName string) (field.OrderExpr, bool) {
	_f, ok := s.fieldMap[fieldName]
	if !ok || _f == nil {
		return nil, false
	}
	_oe, ok := _f.(field.OrderExpr)
	return _oe, ok
}

func (s *scrapingWorkflowORM) fillFieldMap() {
	s.fieldMap = make(map[string]field.Expr, 46)
	s.fieldMap["accept_terms_of_service"] = s.AcceptTermsOfService
	s.fieldMap["alert_emails"] = s.AlertEmails
	s.fieldMap["anonymize_pii"] = s.AnonymizePii
	s.fieldMap["content_filter_allowed_countries"] = s.ContentFilterAllowedCountries
	s.fieldMap["content_filter_excluded_types"] = s.ContentFilterExcludedTypes
	s.fieldMap["content_filter_minimum_rating"] = s.ContentFilterMinimumRating
	s.fieldMap["content_filter_minimum_reviews"] = s.ContentFilterMinimumReviews
	s.fieldMap["created_at"] = s.CreatedAt
	s.fieldMap["cron_expression"] = s.CronExpression
	s.fieldMap["data_retention"] = s.DataRetention
	s.fieldMap["deleted_at"] = s.DeletedAt
	s.fieldMap["geo_fencing_lat"] = s.GeoFencingLat
	s.fieldMap["geo_fencing_lon"] = s.GeoFencingLon
	s.fieldMap["geo_fencing_radius"] = s.GeoFencingRadius
	s.fieldMap["geo_fencing_zoom_max"] = s.GeoFencingZoomMax
	s.fieldMap["geo_fencing_zoom_min"] = s.GeoFencingZoomMin
	s.fieldMap["id"] = s.Id
	s.fieldMap["include_business_hours"] = s.IncludeBusinessHours
	s.fieldMap["include_photos"] = s.IncludePhotos
	s.fieldMap["include_reviews"] = s.IncludeReviews
	s.fieldMap["last_run_time"] = s.LastRunTime
	s.fieldMap["max_retries"] = s.MaxRetries
	s.fieldMap["max_reviews_per_business"] = s.MaxReviewsPerBusiness
	s.fieldMap["next_run_time"] = s.NextRunTime
	s.fieldMap["notification_email_group"] = s.NotificationEmailGroup
	s.fieldMap["notification_notify_on_complete"] = s.NotificationNotifyOnComplete
	s.fieldMap["notification_notify_on_failure"] = s.NotificationNotifyOnFailure
	s.fieldMap["notification_notify_on_start"] = s.NotificationNotifyOnStart
	s.fieldMap["notification_slack_channel"] = s.NotificationSlackChannel
	s.fieldMap["notification_webhook_url"] = s.NotificationWebhookUrl
	s.fieldMap["org_id"] = s.OrgId
	s.fieldMap["output_destination"] = s.OutputDestination
	s.fieldMap["output_format"] = s.OutputFormat
	s.fieldMap["qos_enable_javascript"] = s.QosEnableJavascript
	s.fieldMap["qos_max_concurrent_requests"] = s.QosMaxConcurrentRequests
	s.fieldMap["qos_max_retries"] = s.QosMaxRetries
	s.fieldMap["qos_request_timeout"] = s.QosRequestTimeout
	s.fieldMap["respect_robots_txt"] = s.RespectRobotsTxt
	s.fieldMap["retry_count"] = s.RetryCount
	s.fieldMap["status"] = s.Status
	s.fieldMap["tenant_id"] = s.TenantId
	s.fieldMap["updated_at"] = s.UpdatedAt
	s.fieldMap["user_agent"] = s.UserAgent
	s.fieldMap["workspace_id"] = s.WorkspaceId

}

func (s scrapingWorkflowORM) clone(db *gorm.DB) scrapingWorkflowORM {
	s.scrapingWorkflowORMDo.ReplaceConnPool(db.Statement.ConnPool)
	return s
}

func (s scrapingWorkflowORM) replaceDB(db *gorm.DB) scrapingWorkflowORM {
	s.scrapingWorkflowORMDo.ReplaceDB(db)
	return s
}

type scrapingWorkflowORMHasManyJobs struct {
	db *gorm.DB

	field.RelationField

	Leads struct {
		field.RelationField
		Job struct {
			field.RelationField
		}
		Workspace struct {
			field.RelationField
			Workflows struct {
				field.RelationField
				Workspace struct {
					field.RelationField
				}
				Jobs struct {
					field.RelationField
				}
			}
		}
		RegularHours struct {
			field.RelationField
		}
		Reviews struct {
			field.RelationField
		}
		SpecialHours struct {
			field.RelationField
		}
	}
}

func (a scrapingWorkflowORMHasManyJobs) Where(conds ...field.Expr) *scrapingWorkflowORMHasManyJobs {
	if len(conds) == 0 {
		return &a
	}

	exprs := make([]clause.Expression, 0, len(conds))
	for _, cond := range conds {
		exprs = append(exprs, cond.BeCond().(clause.Expression))
	}
	a.db = a.db.Clauses(clause.Where{Exprs: exprs})
	return &a
}

func (a scrapingWorkflowORMHasManyJobs) WithContext(ctx context.Context) *scrapingWorkflowORMHasManyJobs {
	a.db = a.db.WithContext(ctx)
	return &a
}

func (a scrapingWorkflowORMHasManyJobs) Session(session *gorm.Session) *scrapingWorkflowORMHasManyJobs {
	a.db = a.db.Session(session)
	return &a
}

func (a scrapingWorkflowORMHasManyJobs) Model(m *lead_scraper_servicev1.ScrapingWorkflowORM) *scrapingWorkflowORMHasManyJobsTx {
	return &scrapingWorkflowORMHasManyJobsTx{a.db.Model(m).Association(a.Name())}
}

type scrapingWorkflowORMHasManyJobsTx struct{ tx *gorm.Association }

func (a scrapingWorkflowORMHasManyJobsTx) Find() (result []*lead_scraper_servicev1.ScrapingJobORM, err error) {
	return result, a.tx.Find(&result)
}

func (a scrapingWorkflowORMHasManyJobsTx) Append(values ...*lead_scraper_servicev1.ScrapingJobORM) (err error) {
	targetValues := make([]interface{}, len(values))
	for i, v := range values {
		targetValues[i] = v
	}
	return a.tx.Append(targetValues...)
}

func (a scrapingWorkflowORMHasManyJobsTx) Replace(values ...*lead_scraper_servicev1.ScrapingJobORM) (err error) {
	targetValues := make([]interface{}, len(values))
	for i, v := range values {
		targetValues[i] = v
	}
	return a.tx.Replace(targetValues...)
}

func (a scrapingWorkflowORMHasManyJobsTx) Delete(values ...*lead_scraper_servicev1.ScrapingJobORM) (err error) {
	targetValues := make([]interface{}, len(values))
	for i, v := range values {
		targetValues[i] = v
	}
	return a.tx.Delete(targetValues...)
}

func (a scrapingWorkflowORMHasManyJobsTx) Clear() error {
	return a.tx.Clear()
}

func (a scrapingWorkflowORMHasManyJobsTx) Count() int64 {
	return a.tx.Count()
}

type scrapingWorkflowORMBelongsToWorkspace struct {
	db *gorm.DB

	field.RelationField
}

func (a scrapingWorkflowORMBelongsToWorkspace) Where(conds ...field.Expr) *scrapingWorkflowORMBelongsToWorkspace {
	if len(conds) == 0 {
		return &a
	}

	exprs := make([]clause.Expression, 0, len(conds))
	for _, cond := range conds {
		exprs = append(exprs, cond.BeCond().(clause.Expression))
	}
	a.db = a.db.Clauses(clause.Where{Exprs: exprs})
	return &a
}

func (a scrapingWorkflowORMBelongsToWorkspace) WithContext(ctx context.Context) *scrapingWorkflowORMBelongsToWorkspace {
	a.db = a.db.WithContext(ctx)
	return &a
}

func (a scrapingWorkflowORMBelongsToWorkspace) Session(session *gorm.Session) *scrapingWorkflowORMBelongsToWorkspace {
	a.db = a.db.Session(session)
	return &a
}

func (a scrapingWorkflowORMBelongsToWorkspace) Model(m *lead_scraper_servicev1.ScrapingWorkflowORM) *scrapingWorkflowORMBelongsToWorkspaceTx {
	return &scrapingWorkflowORMBelongsToWorkspaceTx{a.db.Model(m).Association(a.Name())}
}

type scrapingWorkflowORMBelongsToWorkspaceTx struct{ tx *gorm.Association }

func (a scrapingWorkflowORMBelongsToWorkspaceTx) Find() (result *lead_scraper_servicev1.WorkspaceORM, err error) {
	return result, a.tx.Find(&result)
}

func (a scrapingWorkflowORMBelongsToWorkspaceTx) Append(values ...*lead_scraper_servicev1.WorkspaceORM) (err error) {
	targetValues := make([]interface{}, len(values))
	for i, v := range values {
		targetValues[i] = v
	}
	return a.tx.Append(targetValues...)
}

func (a scrapingWorkflowORMBelongsToWorkspaceTx) Replace(values ...*lead_scraper_servicev1.WorkspaceORM) (err error) {
	targetValues := make([]interface{}, len(values))
	for i, v := range values {
		targetValues[i] = v
	}
	return a.tx.Replace(targetValues...)
}

func (a scrapingWorkflowORMBelongsToWorkspaceTx) Delete(values ...*lead_scraper_servicev1.WorkspaceORM) (err error) {
	targetValues := make([]interface{}, len(values))
	for i, v := range values {
		targetValues[i] = v
	}
	return a.tx.Delete(targetValues...)
}

func (a scrapingWorkflowORMBelongsToWorkspaceTx) Clear() error {
	return a.tx.Clear()
}

func (a scrapingWorkflowORMBelongsToWorkspaceTx) Count() int64 {
	return a.tx.Count()
}

type scrapingWorkflowORMDo struct{ gen.DO }

type IScrapingWorkflowORMDo interface {
	gen.SubQuery
	Debug() IScrapingWorkflowORMDo
	WithContext(ctx context.Context) IScrapingWorkflowORMDo
	WithResult(fc func(tx gen.Dao)) gen.ResultInfo
	ReplaceDB(db *gorm.DB)
	ReadDB() IScrapingWorkflowORMDo
	WriteDB() IScrapingWorkflowORMDo
	As(alias string) gen.Dao
	Session(config *gorm.Session) IScrapingWorkflowORMDo
	Columns(cols ...field.Expr) gen.Columns
	Clauses(conds ...clause.Expression) IScrapingWorkflowORMDo
	Not(conds ...gen.Condition) IScrapingWorkflowORMDo
	Or(conds ...gen.Condition) IScrapingWorkflowORMDo
	Select(conds ...field.Expr) IScrapingWorkflowORMDo
	Where(conds ...gen.Condition) IScrapingWorkflowORMDo
	Order(conds ...field.Expr) IScrapingWorkflowORMDo
	Distinct(cols ...field.Expr) IScrapingWorkflowORMDo
	Omit(cols ...field.Expr) IScrapingWorkflowORMDo
	Join(table schema.Tabler, on ...field.Expr) IScrapingWorkflowORMDo
	LeftJoin(table schema.Tabler, on ...field.Expr) IScrapingWorkflowORMDo
	RightJoin(table schema.Tabler, on ...field.Expr) IScrapingWorkflowORMDo
	Group(cols ...field.Expr) IScrapingWorkflowORMDo
	Having(conds ...gen.Condition) IScrapingWorkflowORMDo
	Limit(limit int) IScrapingWorkflowORMDo
	Offset(offset int) IScrapingWorkflowORMDo
	Count() (count int64, err error)
	Scopes(funcs ...func(gen.Dao) gen.Dao) IScrapingWorkflowORMDo
	Unscoped() IScrapingWorkflowORMDo
	Create(values ...*lead_scraper_servicev1.ScrapingWorkflowORM) error
	CreateInBatches(values []*lead_scraper_servicev1.ScrapingWorkflowORM, batchSize int) error
	Save(values ...*lead_scraper_servicev1.ScrapingWorkflowORM) error
	First() (*lead_scraper_servicev1.ScrapingWorkflowORM, error)
	Take() (*lead_scraper_servicev1.ScrapingWorkflowORM, error)
	Last() (*lead_scraper_servicev1.ScrapingWorkflowORM, error)
	Find() ([]*lead_scraper_servicev1.ScrapingWorkflowORM, error)
	FindInBatch(batchSize int, fc func(tx gen.Dao, batch int) error) (results []*lead_scraper_servicev1.ScrapingWorkflowORM, err error)
	FindInBatches(result *[]*lead_scraper_servicev1.ScrapingWorkflowORM, batchSize int, fc func(tx gen.Dao, batch int) error) error
	Pluck(column field.Expr, dest interface{}) error
	Delete(...*lead_scraper_servicev1.ScrapingWorkflowORM) (info gen.ResultInfo, err error)
	Update(column field.Expr, value interface{}) (info gen.ResultInfo, err error)
	UpdateSimple(columns ...field.AssignExpr) (info gen.ResultInfo, err error)
	Updates(value interface{}) (info gen.ResultInfo, err error)
	UpdateColumn(column field.Expr, value interface{}) (info gen.ResultInfo, err error)
	UpdateColumnSimple(columns ...field.AssignExpr) (info gen.ResultInfo, err error)
	UpdateColumns(value interface{}) (info gen.ResultInfo, err error)
	UpdateFrom(q gen.SubQuery) gen.Dao
	Attrs(attrs ...field.AssignExpr) IScrapingWorkflowORMDo
	Assign(attrs ...field.AssignExpr) IScrapingWorkflowORMDo
	Joins(fields ...field.RelationField) IScrapingWorkflowORMDo
	Preload(fields ...field.RelationField) IScrapingWorkflowORMDo
	FirstOrInit() (*lead_scraper_servicev1.ScrapingWorkflowORM, error)
	FirstOrCreate() (*lead_scraper_servicev1.ScrapingWorkflowORM, error)
	FindByPage(offset int, limit int) (result []*lead_scraper_servicev1.ScrapingWorkflowORM, count int64, err error)
	ScanByPage(result interface{}, offset int, limit int) (count int64, err error)
	Scan(result interface{}) (err error)
	Returning(value interface{}, columns ...string) IScrapingWorkflowORMDo
	UnderlyingDB() *gorm.DB
	schema.Tabler

	GetRecordByID(id uint64) (result lead_scraper_servicev1.ScrapingWorkflowORM, err error)
	GetRecordByIDs(ids []uint64) (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error)
	DeleteRecordByID(id uint64) (err error)
	GetAllRecords(orderColumn string, limit int, offset int) (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error)
	CountAll() (result int, err error)
	GetByID(id uint64) (result lead_scraper_servicev1.ScrapingWorkflowORM, err error)
	GetByIDs(ids []uint64) (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error)
	GetActivePaginated(orderColumn string, limit int, offset int) (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error)
	GetDeleted() (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error)
	SoftDelete(id uint64) (err error)
	Restore(id uint64) (err error)
	CreateInBatch(items []lead_scraper_servicev1.ScrapingWorkflowORM, batchSize int) (err error)
	DeleteInBatch(ids []uint64) (err error)
	GetByTimeRange(startTime time.Time, endTime time.Time) (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error)
	FindBy(columnName string, operator string, value interface{}) (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error)
	FindByPattern(columnName string, pattern string) (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error)
	GetDistinct(columnName string) (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error)
	FindWithFilters(conditions map[string]interface{}, orderBy string, limit int, offset int) (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error)
	Touch(id uint64) (err error)
	Exists(column string, value interface{}) (result bool, err error)
	ExistsById(id uint64) (result bool, err error)
	FindBySubquery(column string, foreignTable string, foreignKey string) (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error)
	ExistsAndGet(column string, value interface{}) (result lead_scraper_servicev1.ScrapingWorkflowORM, err error)
	ExistsAndGetActive(column string, value interface{}) (result lead_scraper_servicev1.ScrapingWorkflowORM, err error)
}

// SELECT * FROM @@table
// {{where}}
//
//	id=@id
//
// {{end}}
func (s scrapingWorkflowORMDo) GetRecordByID(id uint64) (result lead_scraper_servicev1.ScrapingWorkflowORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM scraping_workflows ")
	var whereSQL0 strings.Builder
	params = append(params, id)
	whereSQL0.WriteString("id=? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Take(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// {{where}}
//
//	id IN (@ids)
//
// {{end}}
func (s scrapingWorkflowORMDo) GetRecordByIDs(ids []uint64) (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM scraping_workflows ")
	var whereSQL0 strings.Builder
	params = append(params, ids)
	whereSQL0.WriteString("id IN (?) ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// DELETE FROM @@table
// {{where}}
//
//	id=@id
//
// {{end}}
func (s scrapingWorkflowORMDo) DeleteRecordByID(id uint64) (err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("DELETE FROM scraping_workflows ")
	var whereSQL0 strings.Builder
	params = append(params, id)
	whereSQL0.WriteString("id=? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Exec(generateSQL.String(), params...) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// ORDER BY @@orderColumn
// LIMIT @limit
// OFFSET @offset
func (s scrapingWorkflowORMDo) GetAllRecords(orderColumn string, limit int, offset int) (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	params = append(params, limit)
	params = append(params, offset)
	generateSQL.WriteString("SELECT * FROM scraping_workflows ORDER BY " + s.Quote(orderColumn) + " LIMIT ? OFFSET ? ")

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// Additional Operations
// SELECT COUNT(*) FROM @@table
func (s scrapingWorkflowORMDo) CountAll() (result int, err error) {
	var generateSQL strings.Builder
	generateSQL.WriteString("Additional Operations SELECT COUNT(*) FROM scraping_workflows ")

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String()).Take(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// {{where}}
//
//	id=@id
//
// {{end}}
func (s scrapingWorkflowORMDo) GetByID(id uint64) (result lead_scraper_servicev1.ScrapingWorkflowORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM scraping_workflows ")
	var whereSQL0 strings.Builder
	params = append(params, id)
	whereSQL0.WriteString("id=? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Take(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// {{where}}
//
//	id IN (@ids)
//
// {{end}}
func (s scrapingWorkflowORMDo) GetByIDs(ids []uint64) (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM scraping_workflows ")
	var whereSQL0 strings.Builder
	params = append(params, ids)
	whereSQL0.WriteString("id IN (?) ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// {{where}}
//
//	deleted_at IS NULL
//
// {{end}}
// ORDER BY @@orderColumn
// LIMIT @limit OFFSET @offset
func (s scrapingWorkflowORMDo) GetActivePaginated(orderColumn string, limit int, offset int) (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM scraping_workflows ")
	var whereSQL0 strings.Builder
	whereSQL0.WriteString("deleted_at IS NULL ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)
	params = append(params, limit)
	params = append(params, offset)
	generateSQL.WriteString("ORDER BY " + s.Quote(orderColumn) + " LIMIT ? OFFSET ? ")

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// {{where}}
//
//	deleted_at IS NOT NULL
//
// {{end}}
func (s scrapingWorkflowORMDo) GetDeleted() (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error) {
	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM scraping_workflows ")
	var whereSQL0 strings.Builder
	whereSQL0.WriteString("deleted_at IS NOT NULL ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String()).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// UPDATE @@table SET deleted_at=CURRENT_TIMESTAMP
// {{where}}
//
//	id=@id
//
// {{end}}
func (s scrapingWorkflowORMDo) SoftDelete(id uint64) (err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("UPDATE scraping_workflows SET deleted_at=CURRENT_TIMESTAMP ")
	var whereSQL0 strings.Builder
	params = append(params, id)
	whereSQL0.WriteString("id=? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Exec(generateSQL.String(), params...) // ignore_security_alert
	err = executeSQL.Error

	return
}

// UPDATE @@table SET deleted_at=NULL
// {{where}}
//
//	id=@id
//
// {{end}}
func (s scrapingWorkflowORMDo) Restore(id uint64) (err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("UPDATE scraping_workflows SET deleted_at=NULL ")
	var whereSQL0 strings.Builder
	params = append(params, id)
	whereSQL0.WriteString("id=? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Exec(generateSQL.String(), params...) // ignore_security_alert
	err = executeSQL.Error

	return
}

// INSERT INTO @@table (columns) VALUES (values...)
func (s scrapingWorkflowORMDo) CreateInBatch(items []lead_scraper_servicev1.ScrapingWorkflowORM, batchSize int) (err error) {
	var generateSQL strings.Builder
	generateSQL.WriteString("INSERT INTO scraping_workflows (columns) VALUES (values...) ")

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Exec(generateSQL.String()) // ignore_security_alert
	err = executeSQL.Error

	return
}

// DELETE FROM @@table
// {{where}}
//
//	id IN (@ids)
//
// {{end}}
func (s scrapingWorkflowORMDo) DeleteInBatch(ids []uint64) (err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("DELETE FROM scraping_workflows ")
	var whereSQL0 strings.Builder
	params = append(params, ids)
	whereSQL0.WriteString("id IN (?) ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Exec(generateSQL.String(), params...) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// {{where}}
//
//	created_at BETWEEN @startTime AND @endTime
//
// {{end}}
func (s scrapingWorkflowORMDo) GetByTimeRange(startTime time.Time, endTime time.Time) (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM scraping_workflows ")
	var whereSQL0 strings.Builder
	params = append(params, startTime)
	params = append(params, endTime)
	whereSQL0.WriteString("created_at BETWEEN ? AND ? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// {{where}}
//
//	column_name @operator @value
//
// {{end}}
func (s scrapingWorkflowORMDo) FindBy(columnName string, operator string, value interface{}) (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM scraping_workflows ")
	var whereSQL0 strings.Builder
	params = append(params, operator)
	params = append(params, value)
	whereSQL0.WriteString("column_name ?? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// {{where}}
//
//	column_name LIKE @pattern
//
// {{end}}
func (s scrapingWorkflowORMDo) FindByPattern(columnName string, pattern string) (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM scraping_workflows ")
	var whereSQL0 strings.Builder
	params = append(params, pattern)
	whereSQL0.WriteString("column_name LIKE ? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT DISTINCT column_name FROM @@table
func (s scrapingWorkflowORMDo) GetDistinct(columnName string) (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error) {
	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT DISTINCT column_name FROM scraping_workflows ")

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String()).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// {{where}}
//
//	@conditions
//
// {{end}}
// ORDER BY @orderBy
// LIMIT @limit OFFSET @offset
func (s scrapingWorkflowORMDo) FindWithFilters(conditions map[string]interface{}, orderBy string, limit int, offset int) (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM scraping_workflows ")
	var whereSQL0 strings.Builder
	params = append(params, conditions)
	whereSQL0.WriteString("? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)
	params = append(params, orderBy)
	params = append(params, limit)
	params = append(params, offset)
	generateSQL.WriteString("ORDER BY ? LIMIT ? OFFSET ? ")

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// UPDATE @@table SET updated_at=CURRENT_TIMESTAMP
// {{where}}
//
//	id=@id
//
// {{end}}
func (s scrapingWorkflowORMDo) Touch(id uint64) (err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("UPDATE scraping_workflows SET updated_at=CURRENT_TIMESTAMP ")
	var whereSQL0 strings.Builder
	params = append(params, id)
	whereSQL0.WriteString("id=? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Exec(generateSQL.String(), params...) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT EXISTS(
//
//	SELECT 1 FROM @@table
//	 {{where}}
//	     @column = @value
//	 {{end}}
//
// )
func (s scrapingWorkflowORMDo) Exists(column string, value interface{}) (result bool, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT EXISTS( SELECT 1 FROM scraping_workflows ")
	var whereSQL0 strings.Builder
	params = append(params, column)
	params = append(params, value)
	whereSQL0.WriteString("? = ? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)
	generateSQL.WriteString(") ")

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Take(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT EXISTS(
//
//	SELECT 1 FROM @@table
//	 {{where}}
//	     id = @id
//	 {{end}}
//
// )
func (s scrapingWorkflowORMDo) ExistsById(id uint64) (result bool, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT EXISTS( SELECT 1 FROM scraping_workflows ")
	var whereSQL0 strings.Builder
	params = append(params, id)
	whereSQL0.WriteString("id = ? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)
	generateSQL.WriteString(") ")

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Take(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT * FROM @@table
// {{where}}
//
//	@column IN (SELECT @foreignKey FROM @foreignTable)
//
// {{end}}
func (s scrapingWorkflowORMDo) FindBySubquery(column string, foreignTable string, foreignKey string) (result []lead_scraper_servicev1.ScrapingWorkflowORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT * FROM scraping_workflows ")
	var whereSQL0 strings.Builder
	params = append(params, column)
	params = append(params, foreignKey)
	params = append(params, foreignTable)
	whereSQL0.WriteString("? IN (SELECT ? FROM ?) ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Find(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT EXISTS(
//
//	SELECT 1 FROM @@table
//	 {{where}}
//	     @column = @value
//	 {{end}}
//
// ), COALESCE((
//
//	SELECT @column FROM @@table
//	 {{where}}
//	     @column = @value
//	 {{end}}
//	LIMIT 1
//
// ), NULL)
func (s scrapingWorkflowORMDo) ExistsAndGet(column string, value interface{}) (result lead_scraper_servicev1.ScrapingWorkflowORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT EXISTS( SELECT 1 FROM scraping_workflows ")
	var whereSQL0 strings.Builder
	params = append(params, column)
	params = append(params, value)
	whereSQL0.WriteString("? = ? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)
	params = append(params, column)
	generateSQL.WriteString("), COALESCE(( SELECT ? FROM scraping_workflows ")
	var whereSQL1 strings.Builder
	params = append(params, column)
	params = append(params, value)
	whereSQL1.WriteString("? = ? ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL1)
	generateSQL.WriteString("LIMIT 1 ), NULL) ")

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Take(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

// SELECT EXISTS(
//
//	SELECT 1 FROM @@table
//	 {{where}}
//	     @column = @value AND deleted_at IS NULL
//	 {{end}}
//
// ), COALESCE((
//
//	SELECT @column FROM @@table
//	 {{where}}
//	     @column = @value AND deleted_at IS NULL
//	 {{end}}
//	LIMIT 1
//
// ), NULL)
func (s scrapingWorkflowORMDo) ExistsAndGetActive(column string, value interface{}) (result lead_scraper_servicev1.ScrapingWorkflowORM, err error) {
	var params []interface{}

	var generateSQL strings.Builder
	generateSQL.WriteString("SELECT EXISTS( SELECT 1 FROM scraping_workflows ")
	var whereSQL0 strings.Builder
	params = append(params, column)
	params = append(params, value)
	whereSQL0.WriteString("? = ? AND deleted_at IS NULL ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL0)
	params = append(params, column)
	generateSQL.WriteString("), COALESCE(( SELECT ? FROM scraping_workflows ")
	var whereSQL1 strings.Builder
	params = append(params, column)
	params = append(params, value)
	whereSQL1.WriteString("? = ? AND deleted_at IS NULL ")
	helper.JoinWhereBuilder(&generateSQL, whereSQL1)
	generateSQL.WriteString("LIMIT 1 ), NULL) ")

	var executeSQL *gorm.DB
	executeSQL = s.UnderlyingDB().Raw(generateSQL.String(), params...).Take(&result) // ignore_security_alert
	err = executeSQL.Error

	return
}

func (s scrapingWorkflowORMDo) Debug() IScrapingWorkflowORMDo {
	return s.withDO(s.DO.Debug())
}

func (s scrapingWorkflowORMDo) WithContext(ctx context.Context) IScrapingWorkflowORMDo {
	return s.withDO(s.DO.WithContext(ctx))
}

func (s scrapingWorkflowORMDo) ReadDB() IScrapingWorkflowORMDo {
	return s.Clauses(dbresolver.Read)
}

func (s scrapingWorkflowORMDo) WriteDB() IScrapingWorkflowORMDo {
	return s.Clauses(dbresolver.Write)
}

func (s scrapingWorkflowORMDo) Session(config *gorm.Session) IScrapingWorkflowORMDo {
	return s.withDO(s.DO.Session(config))
}

func (s scrapingWorkflowORMDo) Clauses(conds ...clause.Expression) IScrapingWorkflowORMDo {
	return s.withDO(s.DO.Clauses(conds...))
}

func (s scrapingWorkflowORMDo) Returning(value interface{}, columns ...string) IScrapingWorkflowORMDo {
	return s.withDO(s.DO.Returning(value, columns...))
}

func (s scrapingWorkflowORMDo) Not(conds ...gen.Condition) IScrapingWorkflowORMDo {
	return s.withDO(s.DO.Not(conds...))
}

func (s scrapingWorkflowORMDo) Or(conds ...gen.Condition) IScrapingWorkflowORMDo {
	return s.withDO(s.DO.Or(conds...))
}

func (s scrapingWorkflowORMDo) Select(conds ...field.Expr) IScrapingWorkflowORMDo {
	return s.withDO(s.DO.Select(conds...))
}

func (s scrapingWorkflowORMDo) Where(conds ...gen.Condition) IScrapingWorkflowORMDo {
	return s.withDO(s.DO.Where(conds...))
}

func (s scrapingWorkflowORMDo) Order(conds ...field.Expr) IScrapingWorkflowORMDo {
	return s.withDO(s.DO.Order(conds...))
}

func (s scrapingWorkflowORMDo) Distinct(cols ...field.Expr) IScrapingWorkflowORMDo {
	return s.withDO(s.DO.Distinct(cols...))
}

func (s scrapingWorkflowORMDo) Omit(cols ...field.Expr) IScrapingWorkflowORMDo {
	return s.withDO(s.DO.Omit(cols...))
}

func (s scrapingWorkflowORMDo) Join(table schema.Tabler, on ...field.Expr) IScrapingWorkflowORMDo {
	return s.withDO(s.DO.Join(table, on...))
}

func (s scrapingWorkflowORMDo) LeftJoin(table schema.Tabler, on ...field.Expr) IScrapingWorkflowORMDo {
	return s.withDO(s.DO.LeftJoin(table, on...))
}

func (s scrapingWorkflowORMDo) RightJoin(table schema.Tabler, on ...field.Expr) IScrapingWorkflowORMDo {
	return s.withDO(s.DO.RightJoin(table, on...))
}

func (s scrapingWorkflowORMDo) Group(cols ...field.Expr) IScrapingWorkflowORMDo {
	return s.withDO(s.DO.Group(cols...))
}

func (s scrapingWorkflowORMDo) Having(conds ...gen.Condition) IScrapingWorkflowORMDo {
	return s.withDO(s.DO.Having(conds...))
}

func (s scrapingWorkflowORMDo) Limit(limit int) IScrapingWorkflowORMDo {
	return s.withDO(s.DO.Limit(limit))
}

func (s scrapingWorkflowORMDo) Offset(offset int) IScrapingWorkflowORMDo {
	return s.withDO(s.DO.Offset(offset))
}

func (s scrapingWorkflowORMDo) Scopes(funcs ...func(gen.Dao) gen.Dao) IScrapingWorkflowORMDo {
	return s.withDO(s.DO.Scopes(funcs...))
}

func (s scrapingWorkflowORMDo) Unscoped() IScrapingWorkflowORMDo {
	return s.withDO(s.DO.Unscoped())
}

func (s scrapingWorkflowORMDo) Create(values ...*lead_scraper_servicev1.ScrapingWorkflowORM) error {
	if len(values) == 0 {
		return nil
	}
	return s.DO.Create(values)
}

func (s scrapingWorkflowORMDo) CreateInBatches(values []*lead_scraper_servicev1.ScrapingWorkflowORM, batchSize int) error {
	return s.DO.CreateInBatches(values, batchSize)
}

// Save : !!! underlying implementation is different with GORM
// The method is equivalent to executing the statement: db.Clauses(clause.OnConflict{UpdateAll: true}).Create(values)
func (s scrapingWorkflowORMDo) Save(values ...*lead_scraper_servicev1.ScrapingWorkflowORM) error {
	if len(values) == 0 {
		return nil
	}
	return s.DO.Save(values)
}

func (s scrapingWorkflowORMDo) First() (*lead_scraper_servicev1.ScrapingWorkflowORM, error) {
	if result, err := s.DO.First(); err != nil {
		return nil, err
	} else {
		return result.(*lead_scraper_servicev1.ScrapingWorkflowORM), nil
	}
}

func (s scrapingWorkflowORMDo) Take() (*lead_scraper_servicev1.ScrapingWorkflowORM, error) {
	if result, err := s.DO.Take(); err != nil {
		return nil, err
	} else {
		return result.(*lead_scraper_servicev1.ScrapingWorkflowORM), nil
	}
}

func (s scrapingWorkflowORMDo) Last() (*lead_scraper_servicev1.ScrapingWorkflowORM, error) {
	if result, err := s.DO.Last(); err != nil {
		return nil, err
	} else {
		return result.(*lead_scraper_servicev1.ScrapingWorkflowORM), nil
	}
}

func (s scrapingWorkflowORMDo) Find() ([]*lead_scraper_servicev1.ScrapingWorkflowORM, error) {
	result, err := s.DO.Find()
	return result.([]*lead_scraper_servicev1.ScrapingWorkflowORM), err
}

func (s scrapingWorkflowORMDo) FindInBatch(batchSize int, fc func(tx gen.Dao, batch int) error) (results []*lead_scraper_servicev1.ScrapingWorkflowORM, err error) {
	buf := make([]*lead_scraper_servicev1.ScrapingWorkflowORM, 0, batchSize)
	err = s.DO.FindInBatches(&buf, batchSize, func(tx gen.Dao, batch int) error {
		defer func() { results = append(results, buf...) }()
		return fc(tx, batch)
	})
	return results, err
}

func (s scrapingWorkflowORMDo) FindInBatches(result *[]*lead_scraper_servicev1.ScrapingWorkflowORM, batchSize int, fc func(tx gen.Dao, batch int) error) error {
	return s.DO.FindInBatches(result, batchSize, fc)
}

func (s scrapingWorkflowORMDo) Attrs(attrs ...field.AssignExpr) IScrapingWorkflowORMDo {
	return s.withDO(s.DO.Attrs(attrs...))
}

func (s scrapingWorkflowORMDo) Assign(attrs ...field.AssignExpr) IScrapingWorkflowORMDo {
	return s.withDO(s.DO.Assign(attrs...))
}

func (s scrapingWorkflowORMDo) Joins(fields ...field.RelationField) IScrapingWorkflowORMDo {
	for _, _f := range fields {
		s = *s.withDO(s.DO.Joins(_f))
	}
	return &s
}

func (s scrapingWorkflowORMDo) Preload(fields ...field.RelationField) IScrapingWorkflowORMDo {
	for _, _f := range fields {
		s = *s.withDO(s.DO.Preload(_f))
	}
	return &s
}

func (s scrapingWorkflowORMDo) FirstOrInit() (*lead_scraper_servicev1.ScrapingWorkflowORM, error) {
	if result, err := s.DO.FirstOrInit(); err != nil {
		return nil, err
	} else {
		return result.(*lead_scraper_servicev1.ScrapingWorkflowORM), nil
	}
}

func (s scrapingWorkflowORMDo) FirstOrCreate() (*lead_scraper_servicev1.ScrapingWorkflowORM, error) {
	if result, err := s.DO.FirstOrCreate(); err != nil {
		return nil, err
	} else {
		return result.(*lead_scraper_servicev1.ScrapingWorkflowORM), nil
	}
}

func (s scrapingWorkflowORMDo) FindByPage(offset int, limit int) (result []*lead_scraper_servicev1.ScrapingWorkflowORM, count int64, err error) {
	result, err = s.Offset(offset).Limit(limit).Find()
	if err != nil {
		return
	}

	if size := len(result); 0 < limit && 0 < size && size < limit {
		count = int64(size + offset)
		return
	}

	count, err = s.Offset(-1).Limit(-1).Count()
	return
}

func (s scrapingWorkflowORMDo) ScanByPage(result interface{}, offset int, limit int) (count int64, err error) {
	count, err = s.Count()
	if err != nil {
		return
	}

	err = s.Offset(offset).Limit(limit).Scan(result)
	return
}

func (s scrapingWorkflowORMDo) Scan(result interface{}) (err error) {
	return s.DO.Scan(result)
}

func (s scrapingWorkflowORMDo) Delete(models ...*lead_scraper_servicev1.ScrapingWorkflowORM) (result gen.ResultInfo, err error) {
	return s.DO.Delete(models)
}

func (s *scrapingWorkflowORMDo) withDO(do gen.Dao) *scrapingWorkflowORMDo {
	s.DO = *do.(*gen.DO)
	return s
}
